bridge — Today at 5:59 AM
  Hi Benjamin, I found in the config file
  LINES2ATTACK = ["62_58_180", "62_63_160", "48_50_136", "48_53_141", "41_48_131", "39_41_121",
                    "43_44_125", "44_45_126", "34_35_110", "54_58_154"]
  It seems strange for me .... what should I do to find the line's index?

Benjamin D. — Today at 6:00 AM
  Hello,
  Yes indeed we calibrated the opponent to "attack" only these lines
  You have the attribute (accessible in all classes): env.name_line (or obs.name_line, or act.name_line etc.)
  That gives you the name of the powerlines
  
Configuracion opponent neurips 2021:

lines_attacked = ["62_58_180", "62_63_160", "48_50_136", "48_53_141", "41_48_131", "39_41_121",
                  "43_44_125", "44_45_126", "34_35_110", "54_58_154"]

opponent_attack_cooldown = 12  # 1 hour, 1 hour being 12 time steps
opponent_attack_duration = 96  # 8 hours at maximum
opponent_budget_per_ts = 0.17  # opponent_attack_duration / opponent_attack_cooldown + epsilon
opponent_init_budget = 144.  # no need to attack straightfully, it can attack starting at midday the first day


https://ogb.stanford.edu/docs/leader_graphprop/
https://arxiv.org/abs/2005.03675
https://www.cs.mcgill.ca/~wlh/grl_book/


Convertir gif a png:
$ convert Scenario_april_000.gif target.png

Como es que a mi me da de maximo 519 acciones pero PARL dice que lo reduce a 1000 acciones en el paper?

En el PARL me da que hay 494 acciones posibles si hay el print de self_action_space.size().
Sera que las 1000 acciones son combinando varias?.


crisco — 08/10/2021

Quick question about action space size. In the grid2op getting started notebook 4 (04_TrainingAnAgent.ipynb) the random agent encodes actions as integers. Playing around with this I noticed the agent generated numbers from 0-450 inclusive (this is on the rte_case14_redisp environment) 
however when calling env.action_space.n to get the size of the action space this returned the value 157. What is the cause of the mismatch are not all the randomly generated integers unique possible actions?
Benjamin D. — 08/10/2021
Hello,
This is a really good question :blush:

In fact it depends on what you counts, and how you count it.

The action space is both discrete (for topology and line status) and countinuous (for redispatching and curtailment). As far as I know there is no direct definition of "dimensions" in this case. And it all comes down to how you count discrete actions.
For example, you can say you discretize everything (transforming redispatching and curtailment to discrete value) and then you count (because now every actions is discrete you can do that) how many possible different actions you have. This will give 450 or something like that.
Another way is to count it more like "continuous space", which is:
- you got 1 dimension per generator for the redispatching
- 1 dimension per generator for the curtailment (if activated, I don't remember for this env in particular)
- 1 dimension for each powerline (i set it to "connected" or set it to "disconnected" or don't set it at all)
- 1 dimension for each powerline change status
- 1 dimension for each element (set bus)
- 1 dimension for each element (change bus)

And if you count it like that, you get 157, this is the way it's encoded by default in grid2op.
You can also mix things and get pretty much all numbers in between (for example you keep counting the countinuous actions like the second method I mentioned, but counts the unitary actions for the discrete ones)


Idea.. armar 'buckets' segun conexiones del grafico y loads/generators en cada una.
Podemos hacer search para hallar la accion de conexion/desconexion/redispatch que lleve a la mejor bucket ??.

matriz de incidencia/ algo asi ???

grafico siempre igual, ver de no cortar lineas y solo redispatch generators y cambiar buses??


Parametros de competencia:
  "competition": {
    "NO_OVERFLOW_DISCONNECTION":  false, // Se desconecta linea cuando hay supera su termal limit
    "NB_TIMESTEP_OVERFLOW_ALLOWED": 3, // Number of timesteps for which a soft overflow is allowed, default 2. This means that a powerline will be disconnected (if :attr:`.NO_OVERFLOW_DISCONNECTION` is set to ``False``) after 2 time steps above its thermal limit. This is called a "soft overflow".
    "NB_TIMESTEP_COOLDOWN_SUB": 3, // When someone changes the topology of a substations, this number indicates how many timesteps the :class:`grid2op.Agent.BaseAgent` has to wait before being able to modify the topology on this same substation. It has the same behaviour as :attr:`Parameters.NB_TIMESTEP_LINE_STATUS_REMODIF`.
    "NB_TIMESTEP_COOLDOWN_LINE": 3, // When someone acts on a powerline by changing its status (connected / disconnected) this number indicates how many timesteps the :class:`grid2op.Agent.BaseAgent` has to wait before being able to modify this status again. For examle, if this is 1, this means that an BaseAgent can act on status of a powerline 1 out of 2 time step (1 time step it acts, another one it cools down, and the next one it can act again). Having it at 0 it equivalent to deactivate this feature (default).
    "HARD_OVERFLOW_THRESHOLD": 2, // If a the powerflow on a line is above HARD_OVERFLOW_THRESHOLD * thermal limit (and attr:`Parameters.NO_OVERFLOW_DISCONNECTION` is set to ``False``) then it is automatically disconnected, regardless of the number of timesteps it is on overflow). This is called a "hard overflow". This is expressed in relative value of the thermal limits, for example, if for a powerline the `thermal_limit` is 150 and the HARD_OVERFLOW_THRESHOLD is 2.0, then if the flow on the powerline reaches 2 * 150 = 300.0 the powerline the powerline is automatically disconnected.
    "NB_TIMESTEP_RECONNECTION": 12, // Number of timesteps a powerline disconnected for security motives (for example due to :attr:`.NB_TIMESTEP_POWERFLOW_ALLOWED` or :attr:`.HARD_OVERFLOW_THRESHOLD`) will remain disconnected.
    "IGNORE_MIN_UP_DOWN_TIME": true, // Whether or not to ignore the attributes `gen_min_uptime` and `gen_min_downtime`. Basically setting this parameter to ``True``
    "ALLOW_DISPATCH_GEN_SWITCH_OFF": true, // allow dispatch on turned off generator (if ``True`` you can actually dispatch a turned on geenrator)
    "ENV_DC": false,
    "FORECAST_DC": false,
    "MAX_SUB_CHANGED": 1, // Maximum number of substations that can be reconfigured between two consecutive timesteps by an :class:`grid2op.Agent.BaseAgent`. Default value is 1.
    "MAX_LINE_STATUS_CHANGED": 1, // Maximum number of powerlines statuses that can be changed between two consecutive timesteps by an :class:`grid2op.Agent.BaseAgent`. Default value is 1.
    "ALARM_BEST_TIME": 7, // Number of step for which it's best to send an alarm BEFORE a game over
    "ALARM_WINDOW_SIZE": 5 // Number of steps for which it's worth it to give an alarm (if an alarm is send outside of the window `[ALARM_BEST_TIME - ALARM_WINDOW_SIZE, ALARM_BEST_TIME + ALARM_WINDOW_SIZE]` then it does not grant anything
  }


Oponente:

    lines_attacked = ["62_58_180", "62_63_160", "48_50_136", "48_53_141", "41_48_131", "39_41_121",
                  "43_44_125", "44_45_126", "34_35_110", "54_58_154"]
    rho_normalization = [0.45, 0.45, 0.6, 0.35, 0.3, 0.2,
                         0.55, 0.3, 0.45, 0.55]
    opponent_attack_cooldown = 12*24  # 24 hours, 1 hour being 12 time steps
    opponent_attack_duration = 12*4  # 4 hours
    opponent_budget_per_ts = 0.16667  # opponent_attack_duration / opponent_attack_cooldown + epsilon
    opponent_init_budget = 144.  # no need to attack straightfully, it can attack starting at midday the first day
    config = {
        "opponent_attack_cooldown": opponent_attack_cooldown,
        "opponent_attack_duration": opponent_attack_duration,
        "opponent_budget_per_ts": opponent_budget_per_ts,
        "opponent_init_budget": opponent_init_budget,
        "opponent_action_class": PowerlineSetAction,
        "opponent_class": WeightedRandomOpponent,
        "opponent_budget_class": BaseActionBudget,
        'kwargs_opponent': {"lines_attacked": lines_attacked,
                            "rho_normalization": rho_normalization,
                            "attack_period": opponent_attack_cooldown}
    }

- `opponent_attack_cooldown`: give the minimum number of time between two attacks (here 1 attack per day)
- `opponent_attack_duration`: duration for each attack (when a line is attacked, it will not be possible to reconnect
  it for that many steps). In the example it's 4h (so 48 steps)
- `opponent_action_class`: type of the action the opponent will perform (in this case `PowerlineSetAction`)
- `opponent_class`: type of the opponent. Change it at your own risk.
- `opponent_budget_class`: Each attack will cost some budget to the opponent. If no budget, the opponent cannot
  attack. This specifies how the budget are computed. Do not change it.
- `opponent_budget_per_ts`: increase of the budget of the opponent per step. The higher this number, the faster the
  the opponent will regenerate its budget.
- `opponent_init_budget`: initial opponent budget. It is set to 0 to "give" the agent a bit of time before the opponent
  is triggered.
- `kwargs_opponent`: additional information for the opponent. In this case we provide for each grid the powerline it
  can attack.

Factorizar action space:

https://openreview.net/pdf?id=naSAkn2Xo46

black box optimization:

https://dl.acm.org/doi/pdf/10.1145/3377930.3389838


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Idea del problema de que reward al final del episodio seria un problema:

Generar episodios mas chicos a partir de los cuales donde pierde. Hacer que comienze N estados antes de perder y ver que el agente aprenda a resolver esos !.

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

gym parametrizacion de obs:

ALL_ATTR_OBS = ("year", "month", "day", "hour_of_day", "minute_of_hour",
                "day_of_week",
                "gen_p", "gen_q", "gen_v",
                "load_p", "load_q", "load_v",
                "p_or", "q_or", "v_or", "a_or",
                "p_ex", "q_ex", "v_ex", "a_ex",
                "rho", "line_status",
                "timestep_overflow", "topo_vect", "time_before_cooldown_line",
                "time_before_cooldown_sub", "time_next_maintenance",
                "duration_next_maintenance", "target_dispatch", "actual_dispatch",
                "storage_charge", "storage_power_target", "storage_power", "curtailment",
                "curtailment_limit", "thermal_limit",

                "is_alarm_illegal", "time_since_last_alarm", "last_alarm", "attention_budget",
                "was_alarm_used_after_game_over"
                )

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>


State abstraction: https://github.com/anonicml2019/icml_2019_state_abstraction
con codigo: https://github.com/anonicml2019/icml_2019_state_abstraction

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>


Siendo que no hay overflow (max rho < 1), simulate con accion de no hacer nada me da que perderia en el siguiente movimiento. Sin embargo al ejecutarse no termina y sigue ok !!.


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Pregunta:

Por la unica razon por la que no hacemos simulate en las 1255 acciones es porque no da el tiempo de ejecucion ???

Probar devuelta, porque segun lo que veo, simulate funciona suficientemente bien como para que elegir la opcion segun simulate sea mejor que usando q-learning, etc, para predecir la accion
con reward la diferencia de rhos...

Probar si realmente el simulate con 62 da mejor que con 1255 como pensaba antes... 

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Parece que varias de las veces que falla es porque el oponente desconecta una linea y esto causa DivergingPowerFlow.

Podemos hacer que si simulamos el ataque de un oponente tomemos solo acciones que eviten que esto resulte en un DivergingPowerFlow?.

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

1255 actions con redispatch:

$ python3.9 train.py Eval 10 0
$ python3.9 train.py Eval 10 1
$ python3.9 train.py Eval 10 2

Completed episode 9 ,number of timesteps: 3123
Num timesteps 10  survived timesteps: [8062, 305, 2300, 2274, 3093, 411, 239, 546, 5346, 3123]
Average survived timesteps: 2569.9
FINISH!!

Completed episode 9 ,number of timesteps: 8062
Num timesteps 10  survived timesteps: [5987, 1632, 306, 2295, 2276, 123, 235, 8062, 523, 8062]
Average survived timesteps: 2950.1
FINISH!!

Completed episode 9 ,number of timesteps: 2820
Num timesteps 10  survived timesteps: [8062, 10, 5016, 2524, 3737, 296, 8062, 1657, 3098, 2820]
Average survived timesteps: 3528.2
FINISH!!


1255 actions sin redispatch:

$ python3.9 train.py Eval 10 0
$ python3.9 train.py Eval 10 1
$ python3.9 train.py Eval 10 2

Num timesteps 10  survived timesteps: [8062, 305, 2298, 2274, 3093, 409, 193, 546, 5346, 3123]
Average survived timesteps: 2564.9
Memory used (GB): 1.4961051940917969
Environment used: env_val Seed used: 1
FINISH!!

Num timesteps 10  survived timesteps: [5987, 1632, 306, 2295, 2276, 123, 235, 8062, 523, 8062]
Average survived timesteps: 2950.1
Memory used (GB): 1.4903602600097656
Environment used: env_val Seed used: 0
FINISH!!

Num timesteps 10  survived timesteps: [8062, 10, 5016, 2526, 3737, 4896, 8062, 1659, 3103, 2820]
Average survived timesteps: 3989.1
Memory used (GB): 1.5011672973632812
Environment used: env_val Seed used: 2
FINISH!!

62 actions:

$ python3.9 train.py Eval 10 0
$ python3.9 train.py Eval 10 1
$ python3.9 train.py Eval 10 2

Num timesteps 10  survived timesteps: [558, 1632, 305, 5998, 2276, 122, 193, 7788, 523, 8062]
Episodes: ['Scenario_june_254', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_december_024', 'Scenario_june_004', 'Scenario_september_017', 'Scenario_january_183', 'Scenario_november_247', 'Scenario_april_220', 'Scenario_february_149']
-> Average survived timesteps: 2745.7
Memory used (GB): 0.6264724731445312
Environment used: env_val Seed used: 0

Num timesteps 10  survived timesteps: [1650, 305, 9, 2276, 7477, 384, 172, 529, 8062, 3123]
Episodes: ['Scenario_june_254', 'Scenario_april_004', 'Scenario_january_221', 'Scenario_august_195', 'Scenario_october_111', 'Scenario_july_303', 'Scenario_december_067', 'Scenario_january_242', 'Scenario_october_017', 'Scenario_june_318']
-> Average survived timesteps: 2398.7
Memory used (GB): 0.5742263793945312
Environment used: env_val Seed used: 1

Num timesteps 10  survived timesteps: [6583, 9, 3079, 121, 8062, 255, 8062, 1640, 3058, 1184]
Episodes: ['Scenario_january_242', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_april_220', 'Scenario_january_221', 'Scenario_august_210', 'Scenario_october_111', 'Scenario_june_004', 'Scenario_march_106', 'Scenario_october_258']
-> Average survived timesteps: 3205.3
Memory used (GB): 0.58477783203125
Environment used: env_val Seed used: 2

62 + 146 actions:

$ python3.9 train.py Eval 10 0
$ python3.9 train.py Eval 10 1
$ python3.9 train.py Eval 10 2

Episodes: ['Scenario_june_254', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_december_024', 'Scenario_june_004', 'Scenario_september_017', 'Scenario_january_183', 'Scenario_november_247', 'Scenario_april_220', 'Scenario_february_149']
Num timesteps 10  survived timesteps: [5992, 1632, 306, 8062, 2276, 123, 406, 8062, 1561, 8062]
-> Average survived timesteps: 3648.2
Memory used (GB): 0.6933403015136719
Environment used: env_val Seed used: 0
FINISH!!

Completed episode 9 ,number of timesteps: 2818
Episodes: ['Scenario_january_242', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_april_220', 'Scenario_january_221', 'Scenario_august_210', 'Scenario_october_111', 'Scenario_june_004', 'Scenario_march_106', 'Scenario_october_258']
Num timesteps 10  survived timesteps: [8062, 10, 5101, 2522, 8062, 4894, 8062, 1662, 738, 2818]
-> Average survived timesteps: 4193.1
Memory used (GB): 0.7543716430664062
Environment used: env_val Seed used: 2
FINISH!!

Completed episode 9 ,number of timesteps: 3123
Episodes: ['Scenario_june_254', 'Scenario_april_004', 'Scenario_january_221', 'Scenario_august_195', 'Scenario_october_111', 'Scenario_july_303', 'Scenario_december_067', 'Scenario_january_242', 'Scenario_october_017', 'Scenario_june_318']
Num timesteps 10  survived timesteps: [1646, 305, 2300, 2282, 7478, 385, 189, 580, 8062, 3123]
-> Average survived timesteps: 2635.0
Memory used (GB): 0.6797065734863281
Environment used: env_val Seed used: 1
FINISH!!


>>>>>>>>>>>>>>>>>>>


Con buckets (1255 acciones):

$ python3.9 train.py Eval 30 0 & python3.9 train.py Eval 30 1 & python3.9 train.py Eval 30 2 & python3.9 train.py Eval 30 3

Episodes: ['Scenario_june_254', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_december_024', 'Scenario_june_004', 'Scenario_september_017', 'Scenario_january_183', 'Scenario_november_247', 'Scenario_april_220', 'Scenario_february_149', 'Scenario_july_303', 'Scenario_june_318', 'Scenario_august_167', 'Scenario_january_221', 'Scenario_april_113', 'Scenario_august_195', 'Scenario_march_059', 'Scenario_may_137', 'Scenario_january_242', 'Scenario_october_258', 'Scenario_august_210', 'Scenario_december_067', 'Scenario_march_106', 'Scenario_october_111', 'Scenario_october_017', 'Scenario_april_004', 'Scenario_june_243', 'Scenario_april_262', 'Scenario_january_132', 'Scenario_june_254']
Num timesteps 30  survived timesteps: [5987, 1632, 306, 2295, 2276, 123, 235, 8062, 523, 8062, 8062, 2415, 2252, 8062, 494, 1978, 8062, 2381, 2880, 8062, 1130, 2015, 4301, 572, 8062, 6211, 8062, 113, 8062, 8062]
-> Average survived timesteps: 4024.633333333333
Memory used (GB): 1.5031623840332031
Environment used: env_val Seed used: 0

Episodes: ['Scenario_june_254', 'Scenario_april_004', 'Scenario_january_221', 'Scenario_august_195', 'Scenario_october_111', 'Scenario_july_303', 'Scenario_december_067', 'Scenario_january_242', 'Scenario_october_017', 'Scenario_june_318', 'Scenario_march_059', 'Scenario_august_167', 'Scenario_april_262', 'Scenario_november_247', 'Scenario_april_113', 'Scenario_december_024', 'Scenario_august_210', 'Scenario_april_220', 'Scenario_february_149', 'Scenario_october_258', 'Scenario_september_017', 'Scenario_january_183', 'Scenario_june_004', 'Scenario_january_132', 'Scenario_march_106', 'Scenario_june_243', 'Scenario_may_137', 'Scenario_february_132', 'Scenario_august_151', 'Scenario_june_254']
Num timesteps 30  survived timesteps: [8062, 305, 2298, 2274, 3093, 409, 193, 546, 5346, 3123, 2415, 5994, 2286, 8062, 1323, 8062, 5080, 2132, 1652, 1131, 2015, 1307, 410, 8062, 6211, 5981, 1549, 2522, 8062, 2530]
-> Average survived timesteps: 3414.5
Memory used (GB): 1.5023193359375
Environment used: env_val Seed used: 1

Episodes: ['Scenario_january_242', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_april_220', 'Scenario_january_221', 'Scenario_august_210', 'Scenario_october_111', 'Scenario_june_004', 'Scenario_march_106', 'Scenario_october_258', 'Scenario_february_149', 'Scenario_april_004', 'Scenario_august_167', 'Scenario_april_262', 'Scenario_january_183', 'Scenario_december_024', 'Scenario_august_195', 'Scenario_april_113', 'Scenario_march_059', 'Scenario_july_303', 'Scenario_november_247', 'Scenario_may_137', 'Scenario_december_067', 'Scenario_june_243', 'Scenario_october_017', 'Scenario_january_132', 'Scenario_june_318', 'Scenario_september_017', 'Scenario_june_254', 'Scenario_january_242']
Num timesteps 30  survived timesteps: [8062, 10, 5016, 2526, 3737, 4896, 8062, 1659, 3103, 2820, 5999, 8062, 8062, 1975, 1157, 8062, 7132, 1655, 8062, 122, 4293, 533, 8062, 1066, 1275, 2045, 1640, 8062, 508, 2703]
-> Average survived timesteps: 4012.2
Memory used (GB): 1.5135726928710938
Environment used: env_val Seed used: 2


Episodes: ['Scenario_june_318', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_april_262', 'Scenario_april_220', 'Scenario_november_247', 'Scenario_june_254', 'Scenario_december_067', 'Scenario_march_059', 'Scenario_august_210', 'Scenario_january_132', 'Scenario_august_167', 'Scenario_june_004', 'Scenario_march_106', 'Scenario_january_183', 'Scenario_october_017', 'Scenario_january_221', 'Scenario_may_137', 'Scenario_january_242', 'Scenario_december_024', 'Scenario_october_111', 'Scenario_july_303', 'Scenario_october_258', 'Scenario_february_149', 'Scenario_april_113', 'Scenario_june_243', 'Scenario_august_195', 'Scenario_september_017', 'Scenario_april_004', 'Scenario_june_318']
Num timesteps 30  survived timesteps: [8062, 2277, 3092, 3128, 158, 6618, 783, 3123, 6572, 243, 8062, 1116, 1975, 452, 591, 715, 4488, 1132, 971, 4301, 545, 6246, 1054, 8062, 8062, 2531, 2809, 2530, 8062, 1497]
-> Average survived timesteps: 3308.5666666666666
Memory used (GB): 1.5020942687988281
Environment used: env_val Seed used: 3

Sin buckets (y 1255 acciones)

$ python3.9 train.py Eval 30 0 & python3.9 train.py Eval 30 1 & python3.9 train.py Eval 30 2 & python3.9 train.py Eval 30 3

Episodes: ['Scenario_june_254', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_december_024', 'Scenario_june_004', 'Scenario_september_017', 'Scenario_january_183', 'Scenario_november_247', 'Scenario_april_220', 'Scenario_february_149', 'Scenario_july_303', 'Scenario_june_318', 'Scenario_august_167', 'Scenario_january_221', 'Scenario_april_113', 'Scenario_august_195', 'Scenario_march_059', 'Scenario_may_137', 'Scenario_january_242', 'Scenario_october_258', 'Scenario_august_210', 'Scenario_december_067', 'Scenario_march_106', 'Scenario_october_111', 'Scenario_october_017', 'Scenario_april_004', 'Scenario_june_243', 'Scenario_april_262', 'Scenario_january_132', 'Scenario_june_254']
Num timesteps 30  survived timesteps: [5987, 1632, 306, 2295, 2276, 123, 235, 8062, 523, 8062, 8062, 2415, 2252, 8062, 494, 1978, 8062, 2381, 2880, 8062, 1130, 2015, 4301, 572, 8062, 6211, 8062, 113, 8062, 8062]
-> Average survived timesteps: 4024.633333333333
Memory used (GB): 1.5032730102539062
Environment used: env_val Seed used: 0

Episodes: ['Scenario_june_254', 'Scenario_april_004', 'Scenario_january_221', 'Scenario_august_195', 'Scenario_october_111', 'Scenario_july_303', 'Scenario_december_067', 'Scenario_january_242', 'Scenario_october_017', 'Scenario_june_318', 'Scenario_march_059', 'Scenario_august_167', 'Scenario_april_262', 'Scenario_november_247', 'Scenario_april_113', 'Scenario_december_024', 'Scenario_august_210', 'Scenario_april_220', 'Scenario_february_149', 'Scenario_october_258', 'Scenario_september_017', 'Scenario_january_183', 'Scenario_june_004', 'Scenario_january_132', 'Scenario_march_106', 'Scenario_june_243', 'Scenario_may_137', 'Scenario_february_132', 'Scenario_august_151', 'Scenario_june_254']
Num timesteps 30  survived timesteps: [8062, 305, 2298, 2274, 3093, 409, 193, 546, 5346, 3123, 2415, 5994, 2286, 8062, 1323, 8062, 5080, 2132, 1652, 1131, 2015, 1307, 410, 8062, 6211, 5981, 1549, 2522, 8062, 2530]
-> Average survived timesteps: 3414.5
Memory used (GB): 1.5000724792480469
Environment used: env_val Seed used: 1

Episodes: ['Scenario_january_242', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_april_220', 'Scenario_january_221', 'Scenario_august_210', 'Scenario_october_111', 'Scenario_june_004', 'Scenario_march_106', 'Scenario_october_258', 'Scenario_february_149', 'Scenario_april_004', 'Scenario_august_167', 'Scenario_april_262', 'Scenario_january_183', 'Scenario_december_024', 'Scenario_august_195', 'Scenario_april_113', 'Scenario_march_059', 'Scenario_july_303', 'Scenario_november_247', 'Scenario_may_137', 'Scenario_december_067', 'Scenario_june_243', 'Scenario_october_017', 'Scenario_january_132', 'Scenario_june_318', 'Scenario_september_017', 'Scenario_june_254', 'Scenario_january_242']
Num timesteps 30  survived timesteps: [8062, 10, 5016, 2526, 3737, 4896, 8062, 1659, 3103, 2820, 5999, 8062, 8062, 1975, 1157, 8062, 7132, 1655, 8062, 122, 4293, 533, 8062, 1066, 1275, 2045, 1640, 8062, 508, 2703]
-> Average survived timesteps: 4012.2
Memory used (GB): 1.5064888000488281
Environment used: env_val Seed used: 2

Episodes: ['Scenario_june_318', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_april_262', 'Scenario_april_220', 'Scenario_november_247', 'Scenario_june_254', 'Scenario_december_067', 'Scenario_march_059', 'Scenario_august_210', 'Scenario_january_132', 'Scenario_august_167', 'Scenario_june_004', 'Scenario_march_106', 'Scenario_january_183', 'Scenario_october_017', 'Scenario_january_221', 'Scenario_may_137', 'Scenario_january_242', 'Scenario_december_024', 'Scenario_october_111', 'Scenario_july_303', 'Scenario_october_258', 'Scenario_february_149', 'Scenario_april_113', 'Scenario_june_243', 'Scenario_august_195', 'Scenario_september_017', 'Scenario_april_004', 'Scenario_june_318']
Num timesteps 30  survived timesteps: [8062, 2277, 3092, 3128, 158, 6618, 783, 3123, 6572, 243, 8062, 1116, 1975, 452, 591, 715, 4488, 1132, 971, 4301, 545, 6246, 1054, 8062, 8062, 2531, 2809, 2530, 8062, 1497]
-> Average survived timesteps: 3308.5666666666666
Memory used (GB): 1.50189208984375
Environment used: env_val Seed used: 3

Sin buckets (y 62+146 acciones)

$ python3.9 train.py Eval 30 0 & python3.9 train.py Eval 30 1 & python3.9 train.py Eval 30 2 & python3.9 train.py Eval 30 3

Episodes: ['Scenario_june_254', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_december_024', 'Scenario_june_004', 'Scenario_september_017', 'Scenario_january_183', 'Scenario_november_247', 'Scenario_april_220', 'Scenario_february_149', 'Scenario_july_303', 'Scenario_june_318', 'Scenario_august_167', 'Scenario_january_221', 'Scenario_april_113', 'Scenario_august_195', 'Scenario_march_059', 'Scenario_may_137', 'Scenario_january_242', 'Scenario_october_258', 'Scenario_august_210', 'Scenario_december_067', 'Scenario_march_106', 'Scenario_october_111', 'Scenario_october_017', 'Scenario_april_004', 'Scenario_june_243', 'Scenario_april_262', 'Scenario_january_132', 'Scenario_june_254']
Num timesteps 30  survived timesteps: [5992, 1632, 306, 8062, 2276, 123, 406, 8062, 1561, 8062, 8062, 2415, 239, 8062, 3567, 1975, 7134, 2374, 436, 8062, 1130, 2015, 4302, 566, 8062, 8062, 5984, 113, 8062, 2810]
-> Average survived timesteps: 3997.133333333333
Memory used (GB): 0.7247047424316406
Environment used: env_val Seed used: 0

Episodes: ['Scenario_june_254', 'Scenario_april_004', 'Scenario_january_221', 'Scenario_august_195', 'Scenario_october_111', 'Scenario_july_303', 'Scenario_december_067', 'Scenario_january_242', 'Scenario_october_017', 'Scenario_june_318', 'Scenario_march_059', 'Scenario_august_167', 'Scenario_april_262', 'Scenario_november_247', 'Scenario_april_113', 'Scenario_december_024', 'Scenario_august_210', 'Scenario_april_220', 'Scenario_february_149', 'Scenario_october_258', 'Scenario_september_017', 'Scenario_january_183', 'Scenario_june_004', 'Scenario_january_132', 'Scenario_march_106', 'Scenario_june_243', 'Scenario_may_137', 'Scenario_february_132', 'Scenario_august_151', 'Scenario_june_254']
Num timesteps 30  survived timesteps: [1646, 305, 2300, 2282, 7478, 385, 189, 580, 8062, 3123, 2415, 5994, 1538, 8062, 1976, 8062, 7130, 2864, 425, 1131, 2015, 8062, 411, 422, 8062, 5980, 1546, 3098, 8062, 2530]
-> Average survived timesteps: 3537.8333333333335
Memory used (GB): 0.7568702697753906
Environment used: env_val Seed used: 1

Episodes: ['Scenario_january_242', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_april_220', 'Scenario_january_221', 'Scenario_august_210', 'Scenario_october_111', 'Scenario_june_004', 'Scenario_march_106', 'Scenario_october_258', 'Scenario_february_149', 'Scenario_april_004', 'Scenario_august_167', 'Scenario_april_262', 'Scenario_january_183', 'Scenario_december_024', 'Scenario_august_195', 'Scenario_april_113', 'Scenario_march_059', 'Scenario_july_303', 'Scenario_november_247', 'Scenario_may_137', 'Scenario_december_067', 'Scenario_june_243', 'Scenario_october_017', 'Scenario_january_132', 'Scenario_june_318', 'Scenario_september_017', 'Scenario_june_254', 'Scenario_january_242']
Num timesteps 30  survived timesteps: [8062, 10, 5101, 2522, 8062, 4894, 8062, 1662, 738, 2818, 5997, 8062, 8062, 1975, 1144, 8062, 7126, 1653, 8062, 122, 8062, 533, 8062, 887, 1275, 8062, 1605, 8062, 509, 2703]
-> Average survived timesteps: 4398.533333333334
Memory used (GB): 0.7570648193359375
Environment used: env_val Seed used: 2

Episodes: ['Scenario_june_318', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_april_262', 'Scenario_april_220', 'Scenario_november_247', 'Scenario_june_254', 'Scenario_december_067', 'Scenario_march_059', 'Scenario_august_210', 'Scenario_january_132', 'Scenario_august_167', 'Scenario_june_004', 'Scenario_march_106', 'Scenario_january_183', 'Scenario_october_017', 'Scenario_january_221', 'Scenario_may_137', 'Scenario_january_242', 'Scenario_december_024', 'Scenario_october_111', 'Scenario_july_303', 'Scenario_october_258', 'Scenario_february_149', 'Scenario_april_113', 'Scenario_june_243', 'Scenario_august_195', 'Scenario_september_017', 'Scenario_april_004', 'Scenario_june_318']
Num timesteps 30  survived timesteps: [8062, 251, 2536, 3128, 165, 8062, 783, 3123, 6572, 239, 8062, 7503, 1975, 447, 591, 716, 8062, 1132, 971, 4302, 545, 422, 1043, 8062, 8062, 2537, 2811, 2530, 8062, 1497]
-> Average survived timesteps: 3408.4333333333334
Memory used (GB): 0.7658309936523438
Environment used: env_val Seed used: 3


>>>>>>>>>>>>>>>>>>>

1255 vs 46+146
(0.8 min rho)

1255 (0.8 min rho):

$ python3.9 train.py EvalInTraining 50 0 & python3.9 train.py EvalInTraining 50 1

Episodes: ['Scenario_april_034', 'Scenario_february_066', 'Scenario_january_215', 'Scenario_december_238', 'Scenario_october_177', 'Scenario_november_117', 'Scenario_december_004', 'Scenario_february_050', 'Scenario_april_211', 'Scenario_may_059', 'Scenario_december_234', 'Scenario_march_002', 'Scenario_may_027', 'Scenario_december_025', 'Scenario_april_196', 'Scenario_october_087', 'Scenario_march_075', 'Scenario_november_186', 'Scenario_december_138', 'Scenario_december_042', 'Scenario_august_212', 'Scenario_june_270', 'Scenario_march_151', 'Scenario_july_085', 'Scenario_may_275', 'Scenario_august_251', 'Scenario_september_181', 'Scenario_october_197', 'Scenario_october_234', 'Scenario_february_142', 'Scenario_december_267', 'Scenario_may_298', 'Scenario_may_071', 'Scenario_july_353', 'Scenario_november_036', 'Scenario_july_003', 'Scenario_july_265', 'Scenario_february_055', 'Scenario_june_260', 'Scenario_june_242', 'Scenario_december_097', 'Scenario_march_018', 'Scenario_april_130', 'Scenario_march_254', 'Scenario_october_107', 'Scenario_july_130', 'Scenario_december_248', 'Scenario_june_052', 'Scenario_may_010', 'Scenario_june_343']
Num timesteps 50  survived timesteps: [434, 1632, 305, 12, 1025, 504, 384, 316, 4812, 791, 3120, 3684, 1584, 2061, 617, 1961, 151, 111, 2870, 342, 215, 2015, 4287, 187, 3806, 1087, 290, 431, 125, 740, 487, 85, 623, 1381, 787, 4351, 151, 7401, 4279, 582, 327, 650, 1948, 824, 2267, 1070, 552, 3982, 506, 1372]
-> Average survived timesteps: 1470.48
Memory used (GB): 1.5623207092285156
Environment used: env_train Seed used: 0

Episodes: ['Scenario_may_151', 'Scenario_june_096', 'Scenario_april_228', 'Scenario_july_089', 'Scenario_august_121', 'Scenario_november_144', 'Scenario_june_302', 'Scenario_october_193', 'Scenario_january_148', 'Scenario_march_163', 'Scenario_august_246', 'Scenario_february_184', 'Scenario_november_159', 'Scenario_september_156', 'Scenario_december_086', 'Scenario_august_239', 'Scenario_november_174', 'Scenario_september_237', 'Scenario_february_103', 'Scenario_april_149', 'Scenario_february_256', 'Scenario_february_182', 'Scenario_december_079', 'Scenario_october_021', 'Scenario_january_233', 'Scenario_november_085', 'Scenario_december_263', 'Scenario_september_218', 'Scenario_january_116', 'Scenario_august_022', 'Scenario_august_063', 'Scenario_october_068', 'Scenario_july_158', 'Scenario_june_143', 'Scenario_december_042', 'Scenario_february_072', 'Scenario_april_001', 'Scenario_february_116', 'Scenario_march_148', 'Scenario_may_031', 'Scenario_march_242', 'Scenario_february_201', 'Scenario_august_122', 'Scenario_october_136', 'Scenario_december_154', 'Scenario_march_247', 'Scenario_september_020', 'Scenario_november_007', 'Scenario_october_035', 'Scenario_april_058']
Num timesteps 50  survived timesteps: [3784, 303, 2954, 121, 141, 4181, 118, 520, 798, 3120, 218, 413, 1047, 138, 2372, 224, 7130, 699, 1055, 1134, 122, 2049, 279, 740, 260, 768, 1033, 1489, 2082, 487, 84, 623, 217, 1135, 137, 4863, 507, 3948, 579, 302, 653, 1837, 152, 164, 4150, 571, 652, 154, 1053, 570]
-> Average survived timesteps: 1242.6
Memory used (GB): 1.5633430480957031
Environment used: env_train Seed used: 1


46+146 (0.8 min rho):

$ python3.9 train.py EvalInTraining 50 0 & python3.9 train.py EvalInTraining 50 1

Episodes: ['Scenario_april_034', 'Scenario_february_066', 'Scenario_january_215', 'Scenario_december_238', 'Scenario_october_177', 'Scenario_november_117', 'Scenario_december_004', 'Scenario_february_050', 'Scenario_april_211', 'Scenario_may_059', 'Scenario_december_234', 'Scenario_march_002', 'Scenario_may_027', 'Scenario_december_025', 'Scenario_april_196', 'Scenario_october_087', 'Scenario_march_075', 'Scenario_november_186', 'Scenario_december_138', 'Scenario_december_042', 'Scenario_august_212', 'Scenario_june_270', 'Scenario_march_151', 'Scenario_july_085', 'Scenario_may_275', 'Scenario_august_251', 'Scenario_september_181', 'Scenario_october_197', 'Scenario_october_234', 'Scenario_february_142', 'Scenario_december_267', 'Scenario_may_298', 'Scenario_may_071', 'Scenario_july_353', 'Scenario_november_036', 'Scenario_july_003', 'Scenario_july_265', 'Scenario_february_055', 'Scenario_june_260', 'Scenario_june_242', 'Scenario_december_097', 'Scenario_march_018', 'Scenario_april_130', 'Scenario_march_254', 'Scenario_october_107', 'Scenario_july_130', 'Scenario_december_248', 'Scenario_june_052', 'Scenario_may_010', 'Scenario_june_343']
Num timesteps 50  survived timesteps: [412, 1331, 305, 11, 1025, 168, 384, 8062, 8062, 778, 3120, 8062, 786, 7613, 617, 1975, 429, 591, 1023, 1661, 8062, 2015, 8062, 4093, 8062, 1080, 287, 130, 1546, 1040, 8062, 816, 8062, 692, 1169, 6033, 128, 8062, 8062, 582, 349, 3091, 1948, 143, 903, 258, 8062, 2662, 8062, 1372]
-> Average survived timesteps: 2986.2
Memory used (GB): 0.9860992431640625
Environment used: env_train Seed used: 0


Episodes: ['Scenario_may_151', 'Scenario_june_096', 'Scenario_april_228', 'Scenario_july_089', 'Scenario_august_121', 'Scenario_november_144', 'Scenario_june_302', 'Scenario_october_193', 'Scenario_january_148', 'Scenario_march_163', 'Scenario_august_246', 'Scenario_february_184', 'Scenario_november_159', 'Scenario_september_156', 'Scenario_december_086', 'Scenario_august_239', 'Scenario_november_174', 'Scenario_september_237', 'Scenario_february_103', 'Scenario_april_149', 'Scenario_february_256', 'Scenario_february_182', 'Scenario_december_079', 'Scenario_october_021', 'Scenario_january_233', 'Scenario_november_085', 'Scenario_december_263', 'Scenario_september_218', 'Scenario_january_116', 'Scenario_august_022', 'Scenario_august_063', 'Scenario_october_068', 'Scenario_july_158', 'Scenario_june_143', 'Scenario_december_042', 'Scenario_february_072', 'Scenario_april_001', 'Scenario_february_116', 'Scenario_march_148', 'Scenario_may_031', 'Scenario_march_242', 'Scenario_february_201', 'Scenario_august_122', 'Scenario_october_136', 'Scenario_december_154', 'Scenario_march_247', 'Scenario_september_020', 'Scenario_november_007', 'Scenario_october_035', 'Scenario_april_058']
Num timesteps 50  survived timesteps: [4275, 5611, 7562, 154, 420, 8062, 167, 520, 802, 4063, 796, 258, 1046, 614, 7537, 1145, 8062, 2864, 7443, 457, 131, 996, 279, 1085, 160, 711, 1556, 711, 2811, 2556, 84, 8062, 8062, 1023, 525, 4863, 2843, 4281, 2124, 302, 653, 3735, 822, 314, 4241, 603, 117, 190, 3084, 6628]
-> Average survived timesteps: 2508.2
Memory used (GB): 0.9754219055175781
Environment used: env_train Seed used: 1


Ahora con 1.0 min rho:

$ python3.9 train.py EvalInTraining 50 0 & python3.9 train.py EvalInTraining 50 1
(1.0 rho)
1255 buckets

Episodes: ['Scenario_april_034', 'Scenario_february_066', 'Scenario_january_215', 'Scenario_december_238', 'Scenario_october_177', 'Scenario_november_117', 'Scenario_december_004', 'Scenario_february_050', 'Scenario_april_211', 'Scenario_may_059', 'Scenario_december_234', 'Scenario_march_002', 'Scenario_may_027', 'Scenario_december_025', 'Scenario_april_196', 'Scenario_october_087', 'Scenario_march_075', 'Scenario_november_186', 'Scenario_december_138', 'Scenario_december_042', 'Scenario_august_212', 'Scenario_june_270', 'Scenario_march_151', 'Scenario_july_085', 'Scenario_may_275', 'Scenario_august_251', 'Scenario_september_181', 'Scenario_october_197', 'Scenario_october_234', 'Scenario_february_142', 'Scenario_december_267', 'Scenario_may_298', 'Scenario_may_071', 'Scenario_july_353', 'Scenario_november_036', 'Scenario_july_003', 'Scenario_july_265', 'Scenario_february_055', 'Scenario_june_260', 'Scenario_june_242', 'Scenario_december_097', 'Scenario_march_018', 'Scenario_april_130', 'Scenario_march_254', 'Scenario_october_107', 'Scenario_july_130', 'Scenario_december_248', 'Scenario_june_052', 'Scenario_may_010', 'Scenario_june_343']
Num timesteps 50  survived timesteps: [558, 1632, 305, 12, 1030, 168, 382, 8062, 8062, 797, 3123, 6572, 2678, 6520, 617, 1976, 1146, 591, 4748, 1662, 8062, 2015, 1354, 3481, 8062, 8062, 289, 2032, 2500, 1142, 8062, 4929, 8062, 692, 1665, 5701, 1716, 8062, 8062, 582, 2222, 3092, 1948, 824, 8062, 1147, 4296, 2648, 5440, 1372]
-> Average survived timesteps: 3324.48
Memory used (GB): 1.5161514282226562
Environment used: env_train Seed used: 0

Episodes: ['Scenario_may_151', 'Scenario_june_096', 'Scenario_april_228', 'Scenario_july_089', 'Scenario_august_121', 'Scenario_november_144', 'Scenario_june_302', 'Scenario_october_193', 'Scenario_january_148', 'Scenario_march_163', 'Scenario_august_246', 'Scenario_february_184', 'Scenario_november_159', 'Scenario_september_156', 'Scenario_december_086', 'Scenario_august_239', 'Scenario_november_174', 'Scenario_september_237', 'Scenario_february_103', 'Scenario_april_149', 'Scenario_february_256', 'Scenario_february_182', 'Scenario_december_079', 'Scenario_october_021', 'Scenario_january_233', 'Scenario_november_085', 'Scenario_december_263', 'Scenario_september_218', 'Scenario_january_116', 'Scenario_august_022', 'Scenario_august_063', 'Scenario_october_068', 'Scenario_july_158', 'Scenario_june_143', 'Scenario_december_042', 'Scenario_february_072', 'Scenario_april_001', 'Scenario_february_116', 'Scenario_march_148', 'Scenario_may_031', 'Scenario_march_242', 'Scenario_february_201', 'Scenario_august_122', 'Scenario_october_136', 'Scenario_december_154', 'Scenario_march_247', 'Scenario_september_020', 'Scenario_november_007', 'Scenario_october_035', 'Scenario_april_058']
Num timesteps 50  survived timesteps: [8062, 6583, 6643, 2279, 2499, 8062, 167, 524, 801, 4835, 1874, 240, 1043, 617, 8062, 1145, 7130, 2864, 1660, 1131, 2015, 4295, 279, 4913, 265, 1276, 1564, 2496, 2804, 5586, 294, 8062, 7128, 822, 2234, 4863, 515, 3947, 8062, 302, 656, 8062, 103, 832, 7979, 553, 652, 171, 3095, 8062]
-> Average survived timesteps: 3162.16
Memory used (GB): 1.5161819458007812
Environment used: env_train Seed used: 1

$ python3.9 train.py EvalInTraining 50 0 & python3.9 train.py EvalInTraining 50 1
(1.0 rho)
62+142 buckets:

Episodes: ['Scenario_april_034', 'Scenario_february_066', 'Scenario_january_215', 'Scenario_december_238', 'Scenario_october_177', 'Scenario_november_117', 'Scenario_december_004', 'Scenario_february_050', 'Scenario_april_211', 'Scenario_may_059', 'Scenario_december_234', 'Scenario_march_002', 'Scenario_may_027', 'Scenario_december_025', 'Scenario_april_196', 'Scenario_october_087', 'Scenario_march_075', 'Scenario_november_186', 'Scenario_december_138', 'Scenario_december_042', 'Scenario_august_212', 'Scenario_june_270', 'Scenario_march_151', 'Scenario_july_085', 'Scenario_may_275', 'Scenario_august_251', 'Scenario_september_181', 'Scenario_october_197', 'Scenario_october_234', 'Scenario_february_142', 'Scenario_december_267', 'Scenario_may_298', 'Scenario_may_071', 'Scenario_july_353', 'Scenario_november_036', 'Scenario_july_003', 'Scenario_july_265', 'Scenario_february_055', 'Scenario_june_260', 'Scenario_june_242', 'Scenario_december_097', 'Scenario_march_018', 'Scenario_april_130', 'Scenario_march_254', 'Scenario_october_107', 'Scenario_july_130', 'Scenario_december_248', 'Scenario_june_052', 'Scenario_may_010', 'Scenario_june_343']
Num timesteps 50  survived timesteps: [558, 1632, 305, 11, 1659, 168, 384, 8062, 8062, 778, 3123, 8062, 2263, 8062, 617, 1975, 1144, 591, 4729, 1662, 8062, 2018, 8062, 8062, 8062, 8062, 289, 2035, 2500, 1142, 8062, 4929, 8062, 692, 1665, 5701, 737, 8062, 8062, 582, 2222, 3092, 1948, 824, 873, 1127, 8062, 3982, 5440, 1375]
-> Average survived timesteps: 3552.8
Memory used (GB): 0.7999725341796875
Environment used: env_train Seed used: 0

Episodes: ['Scenario_may_151', 'Scenario_june_096', 'Scenario_april_228', 'Scenario_july_089', 'Scenario_august_121', 'Scenario_november_144', 'Scenario_june_302', 'Scenario_october_193', 'Scenario_january_148', 'Scenario_march_163', 'Scenario_august_246', 'Scenario_february_184', 'Scenario_november_159', 'Scenario_september_156', 'Scenario_december_086', 'Scenario_august_239', 'Scenario_november_174', 'Scenario_september_237', 'Scenario_february_103', 'Scenario_april_149', 'Scenario_february_256', 'Scenario_february_182', 'Scenario_december_079', 'Scenario_october_021', 'Scenario_january_233', 'Scenario_november_085', 'Scenario_december_263', 'Scenario_september_218', 'Scenario_january_116', 'Scenario_august_022', 'Scenario_august_063', 'Scenario_october_068', 'Scenario_july_158', 'Scenario_june_143', 'Scenario_december_042', 'Scenario_february_072', 'Scenario_april_001', 'Scenario_february_116', 'Scenario_march_148', 'Scenario_may_031', 'Scenario_march_242', 'Scenario_february_201', 'Scenario_august_122', 'Scenario_october_136', 'Scenario_december_154', 'Scenario_march_247', 'Scenario_september_020', 'Scenario_november_007', 'Scenario_october_035', 'Scenario_april_058']
Num timesteps 50  survived timesteps: [8062, 6583, 6643, 2283, 448, 8062, 186, 524, 796, 4840, 3554, 240, 1068, 617, 8062, 1145, 7133, 734, 1663, 1131, 2015, 4295, 279, 4913, 265, 1277, 2035, 2496, 2808, 5586, 296, 8062, 7128, 822, 2234, 4863, 506, 3948, 8062, 302, 653, 8062, 822, 833, 7978, 553, 652, 192, 3096, 8062]
-> Average survived timesteps: 3137.38
Memory used (GB): 0.8556785583496094
Environment used: env_train Seed used: 1

$ python3.9 train.py EvalInTraining 50 0 & python3.9 train.py EvalInTraining 50 1
(1.0 rho)
62 buckets:

Episodes: ['Scenario_april_034', 'Scenario_february_066', 'Scenario_january_215', 'Scenario_december_238', 'Scenario_october_177', 'Scenario_november_117', 'Scenario_december_004', 'Scenario_february_050', 'Scenario_april_211', 'Scenario_may_059', 'Scenario_december_234', 'Scenario_march_002', 'Scenario_may_027', 'Scenario_december_025', 'Scenario_april_196', 'Scenario_october_087', 'Scenario_march_075', 'Scenario_november_186', 'Scenario_december_138', 'Scenario_december_042', 'Scenario_august_212', 'Scenario_june_270', 'Scenario_march_151', 'Scenario_july_085', 'Scenario_may_275', 'Scenario_august_251', 'Scenario_september_181', 'Scenario_october_197', 'Scenario_october_234', 'Scenario_february_142', 'Scenario_december_267', 'Scenario_may_298', 'Scenario_may_071', 'Scenario_july_353', 'Scenario_november_036', 'Scenario_july_003', 'Scenario_july_265', 'Scenario_february_055', 'Scenario_june_260', 'Scenario_june_242', 'Scenario_december_097', 'Scenario_march_018', 'Scenario_april_130', 'Scenario_march_254', 'Scenario_october_107', 'Scenario_july_130', 'Scenario_december_248', 'Scenario_june_052', 'Scenario_may_010', 'Scenario_june_343']
Num timesteps 50  survived timesteps: [408, 1632, 305, 9, 1021, 124, 384, 286, 527, 783, 3123, 6574, 2251, 2289, 617, 1975, 1142, 591, 166, 1661, 8062, 2015, 8062, 537, 8062, 1070, 284, 2032, 2148, 1131, 2525, 802, 8062, 696, 1145, 5700, 722, 8062, 8062, 581, 302, 3091, 1948, 99, 8062, 1080, 570, 3986, 8062, 1372]
-> Average survived timesteps: 2484.0
Memory used (GB): 0.6331634521484375
Environment used: env_train Seed used: 0

Episodes: ['Scenario_may_151', 'Scenario_june_096', 'Scenario_april_228', 'Scenario_july_089', 'Scenario_august_121', 'Scenario_november_144', 'Scenario_june_302', 'Scenario_october_193', 'Scenario_january_148', 'Scenario_march_163', 'Scenario_august_246', 'Scenario_february_184', 'Scenario_november_159', 'Scenario_september_156', 'Scenario_december_086', 'Scenario_august_239', 'Scenario_november_174', 'Scenario_september_237', 'Scenario_february_103', 'Scenario_april_149', 'Scenario_february_256', 'Scenario_february_182', 'Scenario_december_079', 'Scenario_october_021', 'Scenario_january_233', 'Scenario_november_085', 'Scenario_december_263', 'Scenario_september_218', 'Scenario_january_116', 'Scenario_august_022', 'Scenario_august_063', 'Scenario_october_068', 'Scenario_july_158', 'Scenario_june_143', 'Scenario_december_042', 'Scenario_february_072', 'Scenario_april_001', 'Scenario_february_116', 'Scenario_march_148', 'Scenario_may_031', 'Scenario_march_242', 'Scenario_february_201', 'Scenario_august_122', 'Scenario_october_136', 'Scenario_december_154', 'Scenario_march_247', 'Scenario_september_020', 'Scenario_november_007', 'Scenario_october_035', 'Scenario_april_058']
Num timesteps 50  survived timesteps: [4264, 5098, 8062, 133, 2500, 8062, 177, 523, 783, 3108, 1184, 239, 1043, 617, 1976, 1142, 5383, 721, 1652, 1131, 131, 4295, 278, 434, 263, 1280, 2032, 2143, 2804, 2525, 293, 8062, 8062, 825, 140, 1715, 500, 3386, 8062, 302, 652, 1948, 105, 819, 7939, 553, 652, 187, 1372, 7714]
-> Average survived timesteps: 2345.42
Memory used (GB): 0.7896156311035156
Environment used: env_train Seed used: 1

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Tiempo de guardar info de episodes solo guardando rhos:

Episodes: ['Scenario_april_210', 'Scenario_december_127', 'Scenario_october_189', 'Scenario_july_302', 'Scenario_january_210', 'Scenario_april_023', 'Scenario_march_138', 'Scenario_july_111', 'Scenario_august_094', 'Scenario_august_225']
Num timesteps 10  survived timesteps: [822, 1634, 1936, 4626, 1021, 3097, 3131, 8062, 8062, 8062]
-> Average survived timesteps: 4045.3
Memory used (GB): 0.3209800720214844
Environment used: env_train Seed used: 0
FINISH!!

python3.9 store_episode_data.py EvalInTraining 10 1 0  2397,15s user 1,89s system 99% cpu 40:06,78 total


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Scores al correr $ test_submission:

Your scores are :
(remember these score are not at all an indication of what will be used in codalab, as the data it is tested on are really different):"

                 0             1
0            score     32.782531
1         duration   8716.180912
2  total_operation     45.475044
3  total_attention      3.166667

------------------------------------
         Extra Informations         
------------------------------------
Don't hesitate to have a look at:
        utils/last_submission_results/results.html
        utils/last_submission_results/*.gif
To have high level information about your agent.


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Eval con agente de ahora con alarma mala con 300 episodios:

$ python3.9 train.py Eval 280 1 0

Episodes: ['Scenario_june_116', 'Scenario_september_015', 'Scenario_march_109', 'Scenario_march_194', 'Scenario_august_187', 'Scenario_april_265', 'Scenario_november_104', 'Scenario_may_324', 'Scenario_august_011', 'Scenario_august_199', 'Scenario_october_015', 'Scenario_december_203', 'Scenario_july_090', 'Scenario_september_173', 'Scenario_august_269', 'Scenario_august_115', 'Scenario_september_131', 'Scenario_november_021', 'Scenario_may_164', 'Scenario_march_159', 'Scenario_april_150', 'Scenario_december_103', 'Scenario_november_204', 'Scenario_january_042', 'Scenario_june_015', 'Scenario_july_011', 'Scenario_august_229', 'Scenario_february_197', 'Scenario_september_076', 'Scenario_february_110', 'Scenario_october_213', 'Scenario_june_190', 'Scenario_august_251', 'Scenario_october_143', 'Scenario_april_075', 'Scenario_july_321', 'Scenario_april_252', 'Scenario_november_154', 'Scenario_april_173', 'Scenario_july_326', 'Scenario_september_097', 'Scenario_january_059', 'Scenario_december_122', 'Scenario_february_152', 'Scenario_october_212', 'Scenario_july_145', 'Scenario_march_097', 'Scenario_may_266', 'Scenario_march_201', 'Scenario_august_069', 'Scenario_december_258', 'Scenario_march_081', 'Scenario_march_002', 'Scenario_august_021', 'Scenario_december_143', 'Scenario_december_263', 'Scenario_may_355', 'Scenario_march_144', 'Scenario_june_319', 'Scenario_october_191', 'Scenario_october_088', 'Scenario_november_224', 'Scenario_february_148', 'Scenario_february_127', 'Scenario_november_092', 'Scenario_november_165', 'Scenario_april_143', 'Scenario_july_258', 'Scenario_february_113', 'Scenario_march_093', 'Scenario_august_043', 'Scenario_september_169', 'Scenario_february_005', 'Scenario_july_075', 'Scenario_march_013', 'Scenario_august_034', 'Scenario_april_261', 'Scenario_april_060', 'Scenario_september_265', 'Scenario_november_261', 'Scenario_july_327', 'Scenario_july_180', 'Scenario_august_222', 'Scenario_june_212', 'Scenario_april_207', 'Scenario_may_154', 'Scenario_may_059', 'Scenario_may_350', 'Scenario_october_249', 'Scenario_april_266', 'Scenario_october_205', 'Scenario_april_049', 'Scenario_may_351', 'Scenario_january_088', 'Scenario_may_210', 'Scenario_june_052', 'Scenario_august_266', 'Scenario_november_058', 'Scenario_september_031', 'Scenario_june_222', 'Scenario_may_344', 'Scenario_october_131', 'Scenario_february_134', 'Scenario_december_147', 'Scenario_december_002', 'Scenario_january_133', 'Scenario_december_211', 'Scenario_may_308', 'Scenario_may_286', 'Scenario_october_037', 'Scenario_september_162', 'Scenario_april_133', 'Scenario_march_045', 'Scenario_april_005', 'Scenario_february_195', 'Scenario_april_257', 'Scenario_june_206', 'Scenario_june_267', 'Scenario_may_180', 'Scenario_september_213', 'Scenario_november_079', 'Scenario_december_128', 'Scenario_february_136', 'Scenario_february_133', 'Scenario_september_116', 'Scenario_august_048', 'Scenario_february_072', 'Scenario_may_101', 'Scenario_april_035', 'Scenario_february_084', 'Scenario_january_036', 'Scenario_february_013', 'Scenario_august_133', 'Scenario_september_132', 'Scenario_june_335', 'Scenario_october_119', 'Scenario_october_269', 'Scenario_december_053', 'Scenario_may_041', 'Scenario_september_196', 'Scenario_august_240', 'Scenario_december_205', 'Scenario_november_024', 'Scenario_january_031', 'Scenario_march_218', 'Scenario_march_242', 'Scenario_february_040', 'Scenario_june_336', 'Scenario_october_241', 'Scenario_january_201', 'Scenario_february_126', 'Scenario_january_021', 'Scenario_february_155', 'Scenario_february_214', 'Scenario_july_261', 'Scenario_august_208', 'Scenario_april_085', 'Scenario_january_250', 'Scenario_october_176', 'Scenario_september_079', 'Scenario_december_054', 'Scenario_april_264', 'Scenario_april_084', 'Scenario_august_247', 'Scenario_november_117', 'Scenario_may_095', 'Scenario_march_059', 'Scenario_december_228', 'Scenario_september_263', 'Scenario_february_103', 'Scenario_september_206', 'Scenario_december_155', 'Scenario_january_130', 'Scenario_march_132', 'Scenario_march_148', 'Scenario_september_224', 'Scenario_december_242', 'Scenario_june_353', 'Scenario_december_057', 'Scenario_december_024', 'Scenario_november_093', 'Scenario_june_247', 'Scenario_september_024', 'Scenario_june_214', 'Scenario_june_171', 'Scenario_july_000', 'Scenario_january_217', 'Scenario_february_162', 'Scenario_october_174', 'Scenario_december_212', 'Scenario_august_254', 'Scenario_october_035', 'Scenario_march_227', 'Scenario_april_024', 'Scenario_august_092', 'Scenario_june_042', 'Scenario_september_055', 'Scenario_november_033', 'Scenario_december_236', 'Scenario_january_256', 'Scenario_december_255', 'Scenario_january_195', 'Scenario_march_018', 'Scenario_february_258', 'Scenario_march_200', 'Scenario_may_249', 'Scenario_january_052', 'Scenario_march_245', 'Scenario_august_204', 'Scenario_may_042', 'Scenario_july_251', 'Scenario_september_159', 'Scenario_may_352', 'Scenario_june_058', 'Scenario_december_161', 'Scenario_december_207', 'Scenario_august_165', 'Scenario_september_057', 'Scenario_january_142', 'Scenario_january_178', 'Scenario_february_037', 'Scenario_december_197', 'Scenario_june_124', 'Scenario_april_153', 'Scenario_july_262', 'Scenario_december_192', 'Scenario_march_232', 'Scenario_may_190', 'Scenario_july_055', 'Scenario_july_165', 'Scenario_march_134', 'Scenario_november_135', 'Scenario_january_204', 'Scenario_december_217', 'Scenario_february_154', 'Scenario_august_126', 'Scenario_november_113', 'Scenario_may_326', 'Scenario_february_066', 'Scenario_october_245', 'Scenario_august_012', 'Scenario_november_141', 'Scenario_march_145', 'Scenario_march_249', 'Scenario_february_157', 'Scenario_september_186', 'Scenario_june_226', 'Scenario_june_283', 'Scenario_february_139', 'Scenario_january_251', 'Scenario_january_022', 'Scenario_january_026', 'Scenario_march_223', 'Scenario_january_041', 'Scenario_january_192', 'Scenario_november_014', 'Scenario_june_354', 'Scenario_january_143', 'Scenario_july_081', 'Scenario_december_175', 'Scenario_january_065', 'Scenario_march_208', 'Scenario_june_011', 'Scenario_august_209', 'Scenario_july_060', 'Scenario_january_190', 'Scenario_may_356', 'Scenario_september_239', 'Scenario_may_263', 'Scenario_january_212', 'Scenario_may_175', 'Scenario_january_003', 'Scenario_june_188', 'Scenario_january_015', 'Scenario_may_274', 'Scenario_may_338', 'Scenario_january_014', 'Scenario_december_152', 'Scenario_june_342', 'Scenario_january_045']
Num timesteps 280  survived timesteps: [1953, 1648, 307, 14, 2277, 7161, 499, 8062, 8062, 8062, 3081, 1187, 8062, 2285, 635, 8062, 7124, 591, 8062, 1653, 8062, 975, 1920, 535, 8062, 8062, 3478, 120, 8062, 2789, 2525, 8062, 8062, 2218, 1674, 6033, 7599, 2847, 5456, 8062, 302, 652, 1570, 822, 288, 8062, 553, 4023, 2259, 8062, 361, 2232, 8062, 2268, 1370, 2491, 8062, 4610, 6058, 1180, 1372, 753, 15, 2447, 3573, 147, 7702, 3487, 1388, 6804, 8062, 8062, 288, 8062, 826, 8062, 7171, 7764, 815, 1178, 8062, 8062, 1551, 8062, 337, 8062, 3990, 8062, 285, 8062, 1337, 5141, 5985, 2452, 8062, 8062, 8062, 1948, 8062, 8062, 8062, 808, 601, 813, 617, 1242, 281, 3782, 8062, 125, 511, 8062, 5154, 4831, 270, 3697, 6342, 8062, 2923, 1098, 927, 247, 1065, 189, 5136, 3789, 4259, 8062, 8062, 502, 204, 1144, 4929, 6568, 8062, 938, 1105, 2484, 8062, 3393, 8062, 1039, 1573, 923, 6522, 936, 165, 8062, 1118, 366, 1821, 549, 593, 2391, 8062, 8062, 2360, 227, 1405, 3084, 1396, 6009, 460, 4263, 594, 8062, 481, 1381, 4957, 1900, 848, 561, 1718, 2529, 841, 815, 1160, 8062, 1698, 1113, 1216, 6086, 2015, 8062, 8062, 8062, 3385, 627, 168, 884, 8062, 332, 2226, 5679, 2563, 8062, 1429, 391, 74, 725, 1591, 972, 2251, 3605, 214, 8062, 420, 2595, 2835, 8062, 8062, 1645, 8062, 1484, 1106, 647, 2248, 1049, 666, 197, 1924, 1591, 8062, 1075, 8062, 671, 1400, 8062, 8062, 5117, 8062, 1018, 657, 7, 710, 5612, 376, 8062, 1960, 1317, 2811, 762, 207, 8062, 1851, 803, 8062, 8062, 830, 505, 1449, 3261, 1410, 523, 577, 71, 8062, 2526, 8062, 881, 251, 816, 8062, 1678, 8062, 976, 6750, 599, 8062, 506, 8062, 993, 8062, 1374, 8062, 8062, 740, 3107, 8062, 399]
Alarm scores [-200.0, -200.0, 42.666666666666664, 100.0, -200.0, -200.0, -200.0, 100.0, 100.0, 100.0, -200.0, 55.99999999999999, 100.0, -200.0, -200.0, 100.0, 55.99999999999999, -200.0, 100.0, -200.0, 100.0, 96.0, -200.0, -200.0, 100.0, 100.0, 96.0, -200.0, 100.0, -200.0, -200.0, 100.0, 100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, 100.0, -200.0, -200.0, -200.0, -200.0, -200.0, 100.0, -200.0, 84.0, 64.0, 100.0, -200.0, -200.0, 100.0, -200.0, -200.0, -200.0, 100.0, -200.0, -200.0, -200.0, -200.0, -200.0, 55.99999999999999, -200.0, -200.0, -200.0, 36.0, -200.0, 64.0, -200.0, 100.0, 100.0, -200.0, 100.0, 84.0, 100.0, -200.0, -200.0, -200.0, -200.0, 100.0, 100.0, -200.0, 100.0, -200.0, 100.0, -200.0, 100.0, 84.0, 100.0, -200.0, -200.0, 100.0, 64.0, 100.0, 100.0, 100.0, -200.0, 100.0, 100.0, 100.0, -200.0, 36.0, -200.0, -200.0, -200.0, -200.0, -200.0, 100.0, -200.0, -200.0, 100.0, -200.0, -200.0, 36.0, 36.0, -200.0, 100.0, 64.0, -200.0, -200.0, 84.0, -200.0, -200.0, -200.0, -200.0, -200.0, 100.0, 100.0, -200.0, 84.0, 36.0, -200.0, 24.0, 100.0, -200.0, -200.0, -200.0, 100.0, -200.0, 100.0, -200.0, -200.0, 100.0, -200.0, 96.0, -200.0, 100.0, -200.0, 55.99999999999999, -200.0, -200.0, -200.0, 36.0, 100.0, 100.0, 96.0, -200.0, -200.0, -200.0, -200.0, -200.0, 42.666666666666664, 84.0, 96.0, 100.0, -200.0, 36.0, 42.666666666666664, 36.0, -200.0, -200.0, -200.0, 55.99999999999999, -200.0, -200.0, -200.0, 100.0, -200.0, 96.0, -200.0, -200.0, -200.0, 100.0, 100.0, 100.0, -200.0, 36.0, -200.0, 96.0, 100.0, 84.0, -200.0, -200.0, 84.0, 100.0, -200.0, -200.0, -200.0, 64.0, -200.0, -200.0, -200.0, -200.0, 64.0, 100.0, -200.0, 84.0, -200.0, 100.0, 100.0, -200.0, 100.0, -200.0, -200.0, -200.0, -200.0, -200.0, 100.0, -200.0, -200.0, 64.0, 100.0, 100.0, 100.0, 96.0, 36.0, 100.0, 100.0, 84.0, 100.0, 64.0, -200.0, 36.0, 36.0, -200.0, -200.0, 100.0, -200.0, -200.0, 24.0, 36.0, 96.0, 100.0, 96.0, -200.0, 100.0, 100.0, 36.0, -200.0, -200.0, 36.0, -200.0, 84.0, -200.0, -200.0, 100.0, -200.0, 100.0, -200.0, -200.0, 84.0, 100.0, -200.0, 100.0, -200.0, 36.0, -200.0, 100.0, -200.0, 100.0, -200.0, 100.0, -200.0, 100.0, 100.0, -200.0, -200.0, 100.0, -200.0]
-> Average survived timesteps: 3586.260714285714
-> Average alarm score: -62.81428571428572


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

We want to avoid the last agent action being on the last timestep because the alarm thinks the game over was because of our action !!!!


Con la primera tanda de rhos 
Moralejas:

- Parece haber varios donde tener 0.9 en vez de 0.8 es un problema, paso en algunos que subia muy rapido de 0.9 a overflow sin dar lugar a usar la alarma.
(37%)

- Parece ser un problema que si hacemos una accion y en esa jugada se da el game over lo toma como que invalida la alarma !!!
(5%)

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Midiendo bien:

con rho 0.9, de 962 episodios tenemos:

- number_of_alarm_failures_due_to_no_info_in_previous_timesteps: 38,7% (373)
- number_of_alarm_failures_due_to_action_leading_to_game_over: 6,1% (59)

AHORA

con rho 0.8, de 196 episodios tenemos:

- number_of_alarm_failures_due_to_no_info_in_previous_timesteps: 23% (47)
- number_of_alarm_failures_due_to_action_leading_to_game_over: 6,6% (13)

Baja de 38,7% a 23%, OK. Probar con 0,7 ???

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Cosas que tenemos que tener en cuenta para mejorar:

-> min rho
-> Evitar que la accion sea lo que cause el gmae over !

> Usar el hecho de estar bajo ataque para elegir hacer una accion (ademas del criterio de que el rho sea < 1) ??

Agregar a store_episode_data:
- under_attack = info["opponent_attack_line"] is not None and len(info["opponent_attack_line"]) > 0
- obs.time_next_maintenance

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Podemos predecir cuando va a atacar el oponente ????

    'kwargs_opponent': {"lines_attacked": lines_attacked,
                        "attack_every_xxx_hour": 24,
                        "average_attack_duration_hour": 4,
                        "minimum_attack_duration_hour": 1},

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Cantidad que estan 'under_attack' vs no cuando perdemos (Para la alarma):

under_attack: 293
no_under_attack: 26

=> 92% de las veces que perdemos estamos under_attack !!!!

Importante agregar esto entonces:

- under_attack = info["opponent_attack_line"] is not None and len(info["opponent_attack_line"]) > 0
- obs.time_next_maintenance

(directamente meterle info["opponent_attack_line"])

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Hello,
Overflows are divided into two categories:
- the line is in overflow for too long
- the overflow on the line is too high (>200% of its thermal limit, or 150% of its limits, I don't remember)

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

number_of_alarm_failures_due_to_no_info_in_previous_timesteps

con 0.7 de rho tenemos 9% de los scenarios donde no visitamos el timestep 7 posiciones anterior al game over!











>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>> RECTA FINAL >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>


PLAN:

> ~100k de episodios guardados.

Instancia aws:
p3.2xlarge
61 gb de ram

Entonces hagamos que tome chunks de 50 gb de memoria max

1000 episodios: 

- 
-53 GB de ram para procesarlos
- 3,2 GB de data generada


=> 100k episodios:

320 GB data generada


Hacer chunks de a 10.000 scenarios
Tenemos 112768 episodios guardados (de train data) en ec2


-> 100k episodios, 10 datos positivos => 1 millon de datos True
-> 8050 datos negativos => 800 millones de datos False

> LARGO de features: 694



python3 store_episode_data.py Eval 200 10 0 1000



Numero de neurons below:

# Neurons = 500.000.000/(alpha*(694+1))

2<= alpha<= 10

alpha = 5, entonces:

# Neurons = 500.000.000/(alpha*(694+1))

143k neurons !


Three hidden layers, cada una con:

2/3 de los inputs de entrada.

Entonces tendriamos

460 neurons en 3 layers distintas.




Instalar:

$ sudo apt install -y git make screen htop unzip python python3 zsh websockify zip gcc g++ vim awscli python3-pip
$ aws s3 cp s3://l2rpn142 . --recursive
$ sudo apt install nvidia-cuda-toolkit
$ pip install grid2op==1.6.3
$ pip install tensorflow==2.5.0
$ pip install numpy==1.18.4


Copiar archivos:
$ scp -ri /home/horacio/Desktop/cfr.pem /home/horacio/git/competition/L2RPN/src/remove_alarm_features.py root@66.228.38.115:/home/ubuntu/src
$ scp -ri /home/horacio/Desktop/cfr.pem /home/horacio/git/competition/L2RPN/src/nn.py root@66.228.38.115:/home/ubuntu/src


Remove alarm features:
python3 remove_alarm_features.py data/nn_val_data/ && python3 remove_alarm_features.py data/nn_training_data/ && python3 remove_alarm_features.py data/nn_training_data_balanced/ && python3 remove_alarm_features.py data/nn_val_data_balanced/

$ python3 remove_alarm_features.py data/nn_val_data/ 
$ python3 remove_alarm_features.py data/nn_training_data_balanced/ 
$ python3 remove_alarm_features.py data/nn_val_data_balanced/
$ python3 remove_alarm_features.py data/nn_training_data/ 

Verificar CUDA:
nvcc -V

CUDA:

wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/7fa2af80.pub
sudo add-apt-repository "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /"
sudo apt update
sudo apt install -y nvidia-kernel-source-455
sudo apt install -y nvidia-dkms-455
sudo apt install -y nvidia-driver-455
sudo apt install -y cuda-drivers-455
sudo apt install -y cuda-runtime-11-1
sudo apt install -y cuda-11-1
echo 'export PATH=/usr/local/cuda-11.1/bin${PATH:+:${PATH}}' >> $HOME/.bashrc

REQUIRE REINICIAR.

Instalar cudnn:

$ scp -ri /home/horacio/Desktop/cfr.pem /home/horacio/git/competition/L2RPN/src/cudnn-11.4-linux-x64-v8.2.4.15.tgz root@66.228.38.115:/home/ubuntu/src/temp
$ tar -xzvf cudnn-11.4-linux-x64-v8.2.4.15.tgz
$ sudo cp cuda/include/cudnn*.h /usr/local/cuda/include
$ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64
$ sudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*


Ver utilizacion GPU:
$ nvidia-smi -l 3


RUNS:

15:32
$ python3 nn.py model_1 Train Balanced 100 256
16:01
$ python3 nn.py model_1 Eval Balanced 0 0
accuracy: 80.56%
Accuracy of always picking False: 52.04780602447623 %

$ time python3 nn.py model_2 Train Balanced 100 256
real    27m22.008s
$ python3 nn.py model_2 Eval Balanced 0 0
accuracy: 82.32%
Accuracy of always picking False: 52.04780602447623 %


Da mejor sin normalizar que normalizando !!!.

Valdra para los otros modelos tambien??

Probamos model_6 vs model_66 ( y Raw en vez de Balanced)

Buscamos que tarde 2hs cada uno.
16:38
$ time python3 nn.py model_6 Train Raw 1000 128
18:30 (70 epochs)
real    109m5.733s
$ python3 nn.py model_6 Eval Raw 0 0
accuracy: 99.39%
Accuracy of always picking False: 99.45538492186722 %
~18:40
$ time python3 nn.py model_66 Train Raw 1000 128
real    104m14.710s
$ python3 nn.py model_66 Eval Raw 0 0
accuracy: 99.56%
Accuracy of always picking False: 99.45538492186722 %


-----------> Entonces hagamos que directamente use sin normalizar !

-----------> USAMOS BALANCED. (Igual voy a usar pocas iteraciones con 1 solo archivo, asi que no ahce falta usar el otro)

Probamos:
con 2hs de tiempo de entrenamiento

model_1
model_3
model_4
model_5
model_6
model_7

model_7:
20:30 hasta 22:30
$ time python3 nn.py model_7 Train Balanced 1000 128
real    114m35.550s

Dejamos corriendo 6 y 5 y 4:

80 iteraciones de 6 son 2 hs.
Asumo que 80 de 5 tambien son 2 hs.
Dejo corriendo el de 4 hasta 120 por las dudas

$ time python3 nn.py model_6 Train Balanced 80 128 && time python3 nn.py model_5 Train Balanced 80 128 && time python3 nn.py model_4 Train Balanced 120 128

Al final tardaron mucho menos que lo anterior proqeu con balanced tarda menos:

model_6: (80 epochs)
real    50m22.661s
model_5: (80 epochs)
real    57m11.993s
model_4: (120 epochs)
real    71m14.763s

Corro model_3, model_2 y model_1 que son los que falta con ~60 min cada uno

(05:51)
$ time python3 nn.py model_3 Train Balanced 9999 128
real    57m6.123s -> 105 epochs
(06:48)
$ time python3 nn.py model_2 Train Balanced 9999 128
real  54m12.998s
(07:45)
$ time python3 nn.py model_1 Train Balanced 105 128


$ python3.9 eval_alarm.py 1000 naive 

Average alarm score: -2.552957359009629
Ahora con disc_lines_before_cascade:
Average alarm score: -2.3713892709766164

disc_lines_before_cascade parece funcionar ok.


Corremos evaluacion:

$ time python3 nn.py model_1 Eval Balanced 0 0
accuracy: 80.83%
Accuracy of always picking False: 52.04780602447623 %

real    0m11.806s
user    0m7.183s
sys     0m7.163s


$ time python3 nn.py model_2 Eval Balanced 0 0

accuracy: 82.26%
Accuracy of always picking False: 52.04780602447623 %

real    0m8.874s
user    0m6.699s
sys     0m4.650s

$ time python3 nn.py model_3 Eval Balanced 0 0
accuracy: 82.70%
Accuracy of always picking False: 52.04780602447623 %

real    0m9.180s
user    0m7.040s
sys     0m4.705s

$ time python3 nn.py model_4 Eval Balanced 0 0
accuracy: 82.79%
Accuracy of always picking False: 52.04780602447623 %

real    0m8.409s
user    0m6.981s
sys     0m3.922s

$ time python3 nn.py model_5 Eval Balanced 0 0
accuracy: 81.60%
Accuracy of always picking False: 52.04780602447623 %

real    0m8.786s
user    0m7.360s
sys     0m4.100s

$ time python3 nn.py model_6 Eval Balanced 0 0
accuracy: 82.41%
Accuracy of always picking False: 52.04780602447623 %

real    0m8.864s
user    0m7.065s
sys     0m4.293s

$ time python3 nn.py model_7 Eval Balanced 0 0
accuracy: 82.17%
Accuracy of always picking False: 52.04780602447623 %

real    0m8.511s
user    0m6.891s
sys     0m4.124s

>>>>>> model_4 parece el mejor, pero corrio por un poco mas de tiempo que los demas.

******************

>>> model_6 quizas ganaria si lo dejo correr mas tiempo ?? probamos !!
>>> TAMBIEN PROBAR CON model_3 !!!!!!!!!!!

$ time python3 nn.py model_6 Train Balanced 120 128
> accuracy: 82.41%
$ time python3 nn.py model_3 Train Balanced 120 128
$ time python3 nn.py model_3 Eval Balanced 0 0
> accuracy: 82.38%

Despues dejarlo corriendo con batch_size 64 y usamos la de amazon para dejar corriendo mismo modelo pero con Raw en vez de Balanced

model_4 es el elegido entonces!.

>>>> $ python3 nn.py model_4 Train Balanced 99999 64

(eval): python3 nn.py model_4-balanced-?? Eval Balanced 0 0

Despues en aws correr:

CORRIENDO EN AWS:

$ python3 nn.py model_4 Train Raw 5 64

(eval): python3 nn.py model_4-?? Eval Raw 0 0
accuracy: 99.54%
Accuracy of always picking False: 99.45538492186722 %

$ python3.9 tune_alarm.py 100 naive "[[1.0, 1.5], [1.5, 2], [2, 2.5], [2.5, 3]]" "[1.5, 1.25, 1.1, 1.0]" "[7,7,7,7]"
-> 24.58 alarm score

test submission con ^:
0            score    39.032606
1         duration   256.833387
2  total_operation    45.475151
3  total_attention    24.000000

$ python3.9 eval.py Eval 50 1 0 

-> Average survived timesteps: 3999.48
-> Average alarm score: 6.88

>> Verificar que lo de no hacer accion si hay 3 lienas en desconectadas para evitar que nuestra accion cause game over esta funcionando bien <<
( PROBARLO EN EVAL.PY)
