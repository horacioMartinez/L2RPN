bridge — Today at 5:59 AM
  Hi Benjamin, I found in the config file
  LINES2ATTACK = ["62_58_180", "62_63_160", "48_50_136", "48_53_141", "41_48_131", "39_41_121",
                    "43_44_125", "44_45_126", "34_35_110", "54_58_154"]
  It seems strange for me .... what should I do to find the line's index?

Benjamin D. — Today at 6:00 AM
  Hello,
  Yes indeed we calibrated the opponent to "attack" only these lines
  You have the attribute (accessible in all classes): env.name_line (or obs.name_line, or act.name_line etc.)
  That gives you the name of the powerlines
  
Configuracion opponent neurips 2021:

lines_attacked = ["62_58_180", "62_63_160", "48_50_136", "48_53_141", "41_48_131", "39_41_121",
                  "43_44_125", "44_45_126", "34_35_110", "54_58_154"]

opponent_attack_cooldown = 12  # 1 hour, 1 hour being 12 time steps
opponent_attack_duration = 96  # 8 hours at maximum
opponent_budget_per_ts = 0.17  # opponent_attack_duration / opponent_attack_cooldown + epsilon
opponent_init_budget = 144.  # no need to attack straightfully, it can attack starting at midday the first day


https://ogb.stanford.edu/docs/leader_graphprop/
https://arxiv.org/abs/2005.03675
https://www.cs.mcgill.ca/~wlh/grl_book/


Convertir gif a png:
$ convert Scenario_april_000.gif target.png

Como es que a mi me da de maximo 519 acciones pero PARL dice que lo reduce a 1000 acciones en el paper?

En el PARL me da que hay 494 acciones posibles si hay el print de self_action_space.size().
Sera que las 1000 acciones son combinando varias?.


crisco — 08/10/2021

Quick question about action space size. In the grid2op getting started notebook 4 (04_TrainingAnAgent.ipynb) the random agent encodes actions as integers. Playing around with this I noticed the agent generated numbers from 0-450 inclusive (this is on the rte_case14_redisp environment) 
however when calling env.action_space.n to get the size of the action space this returned the value 157. What is the cause of the mismatch are not all the randomly generated integers unique possible actions?
Benjamin D. — 08/10/2021
Hello,
This is a really good question :blush:

In fact it depends on what you counts, and how you count it.

The action space is both discrete (for topology and line status) and countinuous (for redispatching and curtailment). As far as I know there is no direct definition of "dimensions" in this case. And it all comes down to how you count discrete actions.
For example, you can say you discretize everything (transforming redispatching and curtailment to discrete value) and then you count (because now every actions is discrete you can do that) how many possible different actions you have. This will give 450 or something like that.
Another way is to count it more like "continuous space", which is:
- you got 1 dimension per generator for the redispatching
- 1 dimension per generator for the curtailment (if activated, I don't remember for this env in particular)
- 1 dimension for each powerline (i set it to "connected" or set it to "disconnected" or don't set it at all)
- 1 dimension for each powerline change status
- 1 dimension for each element (set bus)
- 1 dimension for each element (change bus)

And if you count it like that, you get 157, this is the way it's encoded by default in grid2op.
You can also mix things and get pretty much all numbers in between (for example you keep counting the countinuous actions like the second method I mentioned, but counts the unitary actions for the discrete ones)


Idea.. armar 'buckets' segun conexiones del grafico y loads/generators en cada una.
Podemos hacer search para hallar la accion de conexion/desconexion/redispatch que lleve a la mejor bucket ??.

matriz de incidencia/ algo asi ???

grafico siempre igual, ver de no cortar lineas y solo redispatch generators y cambiar buses??


Parametros de competencia:
  "competition": {
    "NO_OVERFLOW_DISCONNECTION":  false, // Se desconecta linea cuando hay supera su termal limit
    "NB_TIMESTEP_OVERFLOW_ALLOWED": 3, // Number of timesteps for which a soft overflow is allowed, default 2. This means that a powerline will be disconnected (if :attr:`.NO_OVERFLOW_DISCONNECTION` is set to ``False``) after 2 time steps above its thermal limit. This is called a "soft overflow".
    "NB_TIMESTEP_COOLDOWN_SUB": 3, // When someone changes the topology of a substations, this number indicates how many timesteps the :class:`grid2op.Agent.BaseAgent` has to wait before being able to modify the topology on this same substation. It has the same behaviour as :attr:`Parameters.NB_TIMESTEP_LINE_STATUS_REMODIF`.
    "NB_TIMESTEP_COOLDOWN_LINE": 3, // When someone acts on a powerline by changing its status (connected / disconnected) this number indicates how many timesteps the :class:`grid2op.Agent.BaseAgent` has to wait before being able to modify this status again. For examle, if this is 1, this means that an BaseAgent can act on status of a powerline 1 out of 2 time step (1 time step it acts, another one it cools down, and the next one it can act again). Having it at 0 it equivalent to deactivate this feature (default).
    "HARD_OVERFLOW_THRESHOLD": 2, // If a the powerflow on a line is above HARD_OVERFLOW_THRESHOLD * thermal limit (and attr:`Parameters.NO_OVERFLOW_DISCONNECTION` is set to ``False``) then it is automatically disconnected, regardless of the number of timesteps it is on overflow). This is called a "hard overflow". This is expressed in relative value of the thermal limits, for example, if for a powerline the `thermal_limit` is 150 and the HARD_OVERFLOW_THRESHOLD is 2.0, then if the flow on the powerline reaches 2 * 150 = 300.0 the powerline the powerline is automatically disconnected.
    "NB_TIMESTEP_RECONNECTION": 12, // Number of timesteps a powerline disconnected for security motives (for example due to :attr:`.NB_TIMESTEP_POWERFLOW_ALLOWED` or :attr:`.HARD_OVERFLOW_THRESHOLD`) will remain disconnected.
    "IGNORE_MIN_UP_DOWN_TIME": true, // Whether or not to ignore the attributes `gen_min_uptime` and `gen_min_downtime`. Basically setting this parameter to ``True``
    "ALLOW_DISPATCH_GEN_SWITCH_OFF": true, // allow dispatch on turned off generator (if ``True`` you can actually dispatch a turned on geenrator)
    "ENV_DC": false,
    "FORECAST_DC": false,
    "MAX_SUB_CHANGED": 1, // Maximum number of substations that can be reconfigured between two consecutive timesteps by an :class:`grid2op.Agent.BaseAgent`. Default value is 1.
    "MAX_LINE_STATUS_CHANGED": 1, // Maximum number of powerlines statuses that can be changed between two consecutive timesteps by an :class:`grid2op.Agent.BaseAgent`. Default value is 1.
    "ALARM_BEST_TIME": 7, // Number of step for which it's best to send an alarm BEFORE a game over
    "ALARM_WINDOW_SIZE": 5 // Number of steps for which it's worth it to give an alarm (if an alarm is send outside of the window `[ALARM_BEST_TIME - ALARM_WINDOW_SIZE, ALARM_BEST_TIME + ALARM_WINDOW_SIZE]` then it does not grant anything
  }


Oponente:

    lines_attacked = ["62_58_180", "62_63_160", "48_50_136", "48_53_141", "41_48_131", "39_41_121",
                  "43_44_125", "44_45_126", "34_35_110", "54_58_154"]
    rho_normalization = [0.45, 0.45, 0.6, 0.35, 0.3, 0.2,
                         0.55, 0.3, 0.45, 0.55]
    opponent_attack_cooldown = 12*24  # 24 hours, 1 hour being 12 time steps
    opponent_attack_duration = 12*4  # 4 hours
    opponent_budget_per_ts = 0.16667  # opponent_attack_duration / opponent_attack_cooldown + epsilon
    opponent_init_budget = 144.  # no need to attack straightfully, it can attack starting at midday the first day
    config = {
        "opponent_attack_cooldown": opponent_attack_cooldown,
        "opponent_attack_duration": opponent_attack_duration,
        "opponent_budget_per_ts": opponent_budget_per_ts,
        "opponent_init_budget": opponent_init_budget,
        "opponent_action_class": PowerlineSetAction,
        "opponent_class": WeightedRandomOpponent,
        "opponent_budget_class": BaseActionBudget,
        'kwargs_opponent': {"lines_attacked": lines_attacked,
                            "rho_normalization": rho_normalization,
                            "attack_period": opponent_attack_cooldown}
    }

- `opponent_attack_cooldown`: give the minimum number of time between two attacks (here 1 attack per day)
- `opponent_attack_duration`: duration for each attack (when a line is attacked, it will not be possible to reconnect
  it for that many steps). In the example it's 4h (so 48 steps)
- `opponent_action_class`: type of the action the opponent will perform (in this case `PowerlineSetAction`)
- `opponent_class`: type of the opponent. Change it at your own risk.
- `opponent_budget_class`: Each attack will cost some budget to the opponent. If no budget, the opponent cannot
  attack. This specifies how the budget are computed. Do not change it.
- `opponent_budget_per_ts`: increase of the budget of the opponent per step. The higher this number, the faster the
  the opponent will regenerate its budget.
- `opponent_init_budget`: initial opponent budget. It is set to 0 to "give" the agent a bit of time before the opponent
  is triggered.
- `kwargs_opponent`: additional information for the opponent. In this case we provide for each grid the powerline it
  can attack.

Factorizar action space:

https://openreview.net/pdf?id=naSAkn2Xo46

black box optimization:

https://dl.acm.org/doi/pdf/10.1145/3377930.3389838


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Idea del problema de que reward al final del episodio seria un problema:

Generar episodios mas chicos a partir de los cuales donde pierde. Hacer que comienze N estados antes de perder y ver que el agente aprenda a resolver esos !.

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

gym parametrizacion de obs:

ALL_ATTR_OBS = ("year", "month", "day", "hour_of_day", "minute_of_hour",
                "day_of_week",
                "gen_p", "gen_q", "gen_v",
                "load_p", "load_q", "load_v",
                "p_or", "q_or", "v_or", "a_or",
                "p_ex", "q_ex", "v_ex", "a_ex",
                "rho", "line_status",
                "timestep_overflow", "topo_vect", "time_before_cooldown_line",
                "time_before_cooldown_sub", "time_next_maintenance",
                "duration_next_maintenance", "target_dispatch", "actual_dispatch",
                "storage_charge", "storage_power_target", "storage_power", "curtailment",
                "curtailment_limit", "thermal_limit",

                "is_alarm_illegal", "time_since_last_alarm", "last_alarm", "attention_budget",
                "was_alarm_used_after_game_over"
                )

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>


State abstraction: https://github.com/anonicml2019/icml_2019_state_abstraction
con codigo: https://github.com/anonicml2019/icml_2019_state_abstraction

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>


Siendo que no hay overflow (max rho < 1), simulate con accion de no hacer nada me da que perderia en el siguiente movimiento. Sin embargo al ejecutarse no termina y sigue ok !!.


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Pregunta:

Por la unica razon por la que no hacemos simulate en las 1255 acciones es porque no da el tiempo de ejecucion ???

Probar devuelta, porque segun lo que veo, simulate funciona suficientemente bien como para que elegir la opcion segun simulate sea mejor que usando q-learning, etc, para predecir la accion
con reward la diferencia de rhos...

Probar si realmente el simulate con 62 da mejor que con 1255 como pensaba antes... 

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Parece que varias de las veces que falla es porque el oponente desconecta una linea y esto causa DivergingPowerFlow.

Podemos hacer que si simulamos el ataque de un oponente tomemos solo acciones que eviten que esto resulte en un DivergingPowerFlow?.

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

1255 actions con redispatch:

$ python3.9 train.py Eval 10 0
$ python3.9 train.py Eval 10 1
$ python3.9 train.py Eval 10 2

Completed episode 9 ,number of timesteps: 3123
Num timesteps 10  survived timesteps: [8062, 305, 2300, 2274, 3093, 411, 239, 546, 5346, 3123]
Average survived timesteps: 2569.9
FINISH!!

Completed episode 9 ,number of timesteps: 8062
Num timesteps 10  survived timesteps: [5987, 1632, 306, 2295, 2276, 123, 235, 8062, 523, 8062]
Average survived timesteps: 2950.1
FINISH!!

Completed episode 9 ,number of timesteps: 2820
Num timesteps 10  survived timesteps: [8062, 10, 5016, 2524, 3737, 296, 8062, 1657, 3098, 2820]
Average survived timesteps: 3528.2
FINISH!!


1255 actions sin redispatch:

$ python3.9 train.py Eval 10 0
$ python3.9 train.py Eval 10 1
$ python3.9 train.py Eval 10 2

Num timesteps 10  survived timesteps: [8062, 305, 2298, 2274, 3093, 409, 193, 546, 5346, 3123]
Average survived timesteps: 2564.9
Memory used (GB): 1.4961051940917969
Environment used: env_val Seed used: 1
FINISH!!

Num timesteps 10  survived timesteps: [5987, 1632, 306, 2295, 2276, 123, 235, 8062, 523, 8062]
Average survived timesteps: 2950.1
Memory used (GB): 1.4903602600097656
Environment used: env_val Seed used: 0
FINISH!!

Num timesteps 10  survived timesteps: [8062, 10, 5016, 2526, 3737, 4896, 8062, 1659, 3103, 2820]
Average survived timesteps: 3989.1
Memory used (GB): 1.5011672973632812
Environment used: env_val Seed used: 2
FINISH!!

62 actions:

$ python3.9 train.py Eval 10 0
$ python3.9 train.py Eval 10 1
$ python3.9 train.py Eval 10 2

Num timesteps 10  survived timesteps: [558, 1632, 305, 5998, 2276, 122, 193, 7788, 523, 8062]
Episodes: ['Scenario_june_254', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_december_024', 'Scenario_june_004', 'Scenario_september_017', 'Scenario_january_183', 'Scenario_november_247', 'Scenario_april_220', 'Scenario_february_149']
-> Average survived timesteps: 2745.7
Memory used (GB): 0.6264724731445312
Environment used: env_val Seed used: 0

Num timesteps 10  survived timesteps: [1650, 305, 9, 2276, 7477, 384, 172, 529, 8062, 3123]
Episodes: ['Scenario_june_254', 'Scenario_april_004', 'Scenario_january_221', 'Scenario_august_195', 'Scenario_october_111', 'Scenario_july_303', 'Scenario_december_067', 'Scenario_january_242', 'Scenario_october_017', 'Scenario_june_318']
-> Average survived timesteps: 2398.7
Memory used (GB): 0.5742263793945312
Environment used: env_val Seed used: 1

Num timesteps 10  survived timesteps: [6583, 9, 3079, 121, 8062, 255, 8062, 1640, 3058, 1184]
Episodes: ['Scenario_january_242', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_april_220', 'Scenario_january_221', 'Scenario_august_210', 'Scenario_october_111', 'Scenario_june_004', 'Scenario_march_106', 'Scenario_october_258']
-> Average survived timesteps: 3205.3
Memory used (GB): 0.58477783203125
Environment used: env_val Seed used: 2

62 + 146 actions:

$ python3.9 train.py Eval 10 0
$ python3.9 train.py Eval 10 1
$ python3.9 train.py Eval 10 2

Episodes: ['Scenario_june_254', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_december_024', 'Scenario_june_004', 'Scenario_september_017', 'Scenario_january_183', 'Scenario_november_247', 'Scenario_april_220', 'Scenario_february_149']
Num timesteps 10  survived timesteps: [5992, 1632, 306, 8062, 2276, 123, 406, 8062, 1561, 8062]
-> Average survived timesteps: 3648.2
Memory used (GB): 0.6933403015136719
Environment used: env_val Seed used: 0
FINISH!!

Completed episode 9 ,number of timesteps: 2818
Episodes: ['Scenario_january_242', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_april_220', 'Scenario_january_221', 'Scenario_august_210', 'Scenario_october_111', 'Scenario_june_004', 'Scenario_march_106', 'Scenario_october_258']
Num timesteps 10  survived timesteps: [8062, 10, 5101, 2522, 8062, 4894, 8062, 1662, 738, 2818]
-> Average survived timesteps: 4193.1
Memory used (GB): 0.7543716430664062
Environment used: env_val Seed used: 2
FINISH!!

Completed episode 9 ,number of timesteps: 3123
Episodes: ['Scenario_june_254', 'Scenario_april_004', 'Scenario_january_221', 'Scenario_august_195', 'Scenario_october_111', 'Scenario_july_303', 'Scenario_december_067', 'Scenario_january_242', 'Scenario_october_017', 'Scenario_june_318']
Num timesteps 10  survived timesteps: [1646, 305, 2300, 2282, 7478, 385, 189, 580, 8062, 3123]
-> Average survived timesteps: 2635.0
Memory used (GB): 0.6797065734863281
Environment used: env_val Seed used: 1
FINISH!!


>>>>>>>>>>>>>>>>>>>


Con buckets (1255 acciones):

$ python3.9 train.py Eval 30 0 & python3.9 train.py Eval 30 1 & python3.9 train.py Eval 30 2 & python3.9 train.py Eval 30 3

Episodes: ['Scenario_june_254', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_december_024', 'Scenario_june_004', 'Scenario_september_017', 'Scenario_january_183', 'Scenario_november_247', 'Scenario_april_220', 'Scenario_february_149', 'Scenario_july_303', 'Scenario_june_318', 'Scenario_august_167', 'Scenario_january_221', 'Scenario_april_113', 'Scenario_august_195', 'Scenario_march_059', 'Scenario_may_137', 'Scenario_january_242', 'Scenario_october_258', 'Scenario_august_210', 'Scenario_december_067', 'Scenario_march_106', 'Scenario_october_111', 'Scenario_october_017', 'Scenario_april_004', 'Scenario_june_243', 'Scenario_april_262', 'Scenario_january_132', 'Scenario_june_254']
Num timesteps 30  survived timesteps: [5987, 1632, 306, 2295, 2276, 123, 235, 8062, 523, 8062, 8062, 2415, 2252, 8062, 494, 1978, 8062, 2381, 2880, 8062, 1130, 2015, 4301, 572, 8062, 6211, 8062, 113, 8062, 8062]
-> Average survived timesteps: 4024.633333333333
Memory used (GB): 1.5031623840332031
Environment used: env_val Seed used: 0

Episodes: ['Scenario_june_254', 'Scenario_april_004', 'Scenario_january_221', 'Scenario_august_195', 'Scenario_october_111', 'Scenario_july_303', 'Scenario_december_067', 'Scenario_january_242', 'Scenario_october_017', 'Scenario_june_318', 'Scenario_march_059', 'Scenario_august_167', 'Scenario_april_262', 'Scenario_november_247', 'Scenario_april_113', 'Scenario_december_024', 'Scenario_august_210', 'Scenario_april_220', 'Scenario_february_149', 'Scenario_october_258', 'Scenario_september_017', 'Scenario_january_183', 'Scenario_june_004', 'Scenario_january_132', 'Scenario_march_106', 'Scenario_june_243', 'Scenario_may_137', 'Scenario_february_132', 'Scenario_august_151', 'Scenario_june_254']
Num timesteps 30  survived timesteps: [8062, 305, 2298, 2274, 3093, 409, 193, 546, 5346, 3123, 2415, 5994, 2286, 8062, 1323, 8062, 5080, 2132, 1652, 1131, 2015, 1307, 410, 8062, 6211, 5981, 1549, 2522, 8062, 2530]
-> Average survived timesteps: 3414.5
Memory used (GB): 1.5023193359375
Environment used: env_val Seed used: 1

Episodes: ['Scenario_january_242', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_april_220', 'Scenario_january_221', 'Scenario_august_210', 'Scenario_october_111', 'Scenario_june_004', 'Scenario_march_106', 'Scenario_october_258', 'Scenario_february_149', 'Scenario_april_004', 'Scenario_august_167', 'Scenario_april_262', 'Scenario_january_183', 'Scenario_december_024', 'Scenario_august_195', 'Scenario_april_113', 'Scenario_march_059', 'Scenario_july_303', 'Scenario_november_247', 'Scenario_may_137', 'Scenario_december_067', 'Scenario_june_243', 'Scenario_october_017', 'Scenario_january_132', 'Scenario_june_318', 'Scenario_september_017', 'Scenario_june_254', 'Scenario_january_242']
Num timesteps 30  survived timesteps: [8062, 10, 5016, 2526, 3737, 4896, 8062, 1659, 3103, 2820, 5999, 8062, 8062, 1975, 1157, 8062, 7132, 1655, 8062, 122, 4293, 533, 8062, 1066, 1275, 2045, 1640, 8062, 508, 2703]
-> Average survived timesteps: 4012.2
Memory used (GB): 1.5135726928710938
Environment used: env_val Seed used: 2


Episodes: ['Scenario_june_318', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_april_262', 'Scenario_april_220', 'Scenario_november_247', 'Scenario_june_254', 'Scenario_december_067', 'Scenario_march_059', 'Scenario_august_210', 'Scenario_january_132', 'Scenario_august_167', 'Scenario_june_004', 'Scenario_march_106', 'Scenario_january_183', 'Scenario_october_017', 'Scenario_january_221', 'Scenario_may_137', 'Scenario_january_242', 'Scenario_december_024', 'Scenario_october_111', 'Scenario_july_303', 'Scenario_october_258', 'Scenario_february_149', 'Scenario_april_113', 'Scenario_june_243', 'Scenario_august_195', 'Scenario_september_017', 'Scenario_april_004', 'Scenario_june_318']
Num timesteps 30  survived timesteps: [8062, 2277, 3092, 3128, 158, 6618, 783, 3123, 6572, 243, 8062, 1116, 1975, 452, 591, 715, 4488, 1132, 971, 4301, 545, 6246, 1054, 8062, 8062, 2531, 2809, 2530, 8062, 1497]
-> Average survived timesteps: 3308.5666666666666
Memory used (GB): 1.5020942687988281
Environment used: env_val Seed used: 3

Sin buckets (y 1255 acciones)

$ python3.9 train.py Eval 30 0 & python3.9 train.py Eval 30 1 & python3.9 train.py Eval 30 2 & python3.9 train.py Eval 30 3

Episodes: ['Scenario_june_254', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_december_024', 'Scenario_june_004', 'Scenario_september_017', 'Scenario_january_183', 'Scenario_november_247', 'Scenario_april_220', 'Scenario_february_149', 'Scenario_july_303', 'Scenario_june_318', 'Scenario_august_167', 'Scenario_january_221', 'Scenario_april_113', 'Scenario_august_195', 'Scenario_march_059', 'Scenario_may_137', 'Scenario_january_242', 'Scenario_october_258', 'Scenario_august_210', 'Scenario_december_067', 'Scenario_march_106', 'Scenario_october_111', 'Scenario_october_017', 'Scenario_april_004', 'Scenario_june_243', 'Scenario_april_262', 'Scenario_january_132', 'Scenario_june_254']
Num timesteps 30  survived timesteps: [5987, 1632, 306, 2295, 2276, 123, 235, 8062, 523, 8062, 8062, 2415, 2252, 8062, 494, 1978, 8062, 2381, 2880, 8062, 1130, 2015, 4301, 572, 8062, 6211, 8062, 113, 8062, 8062]
-> Average survived timesteps: 4024.633333333333
Memory used (GB): 1.5032730102539062
Environment used: env_val Seed used: 0

Episodes: ['Scenario_june_254', 'Scenario_april_004', 'Scenario_january_221', 'Scenario_august_195', 'Scenario_october_111', 'Scenario_july_303', 'Scenario_december_067', 'Scenario_january_242', 'Scenario_october_017', 'Scenario_june_318', 'Scenario_march_059', 'Scenario_august_167', 'Scenario_april_262', 'Scenario_november_247', 'Scenario_april_113', 'Scenario_december_024', 'Scenario_august_210', 'Scenario_april_220', 'Scenario_february_149', 'Scenario_october_258', 'Scenario_september_017', 'Scenario_january_183', 'Scenario_june_004', 'Scenario_january_132', 'Scenario_march_106', 'Scenario_june_243', 'Scenario_may_137', 'Scenario_february_132', 'Scenario_august_151', 'Scenario_june_254']
Num timesteps 30  survived timesteps: [8062, 305, 2298, 2274, 3093, 409, 193, 546, 5346, 3123, 2415, 5994, 2286, 8062, 1323, 8062, 5080, 2132, 1652, 1131, 2015, 1307, 410, 8062, 6211, 5981, 1549, 2522, 8062, 2530]
-> Average survived timesteps: 3414.5
Memory used (GB): 1.5000724792480469
Environment used: env_val Seed used: 1

Episodes: ['Scenario_january_242', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_april_220', 'Scenario_january_221', 'Scenario_august_210', 'Scenario_october_111', 'Scenario_june_004', 'Scenario_march_106', 'Scenario_october_258', 'Scenario_february_149', 'Scenario_april_004', 'Scenario_august_167', 'Scenario_april_262', 'Scenario_january_183', 'Scenario_december_024', 'Scenario_august_195', 'Scenario_april_113', 'Scenario_march_059', 'Scenario_july_303', 'Scenario_november_247', 'Scenario_may_137', 'Scenario_december_067', 'Scenario_june_243', 'Scenario_october_017', 'Scenario_january_132', 'Scenario_june_318', 'Scenario_september_017', 'Scenario_june_254', 'Scenario_january_242']
Num timesteps 30  survived timesteps: [8062, 10, 5016, 2526, 3737, 4896, 8062, 1659, 3103, 2820, 5999, 8062, 8062, 1975, 1157, 8062, 7132, 1655, 8062, 122, 4293, 533, 8062, 1066, 1275, 2045, 1640, 8062, 508, 2703]
-> Average survived timesteps: 4012.2
Memory used (GB): 1.5064888000488281
Environment used: env_val Seed used: 2

Episodes: ['Scenario_june_318', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_april_262', 'Scenario_april_220', 'Scenario_november_247', 'Scenario_june_254', 'Scenario_december_067', 'Scenario_march_059', 'Scenario_august_210', 'Scenario_january_132', 'Scenario_august_167', 'Scenario_june_004', 'Scenario_march_106', 'Scenario_january_183', 'Scenario_october_017', 'Scenario_january_221', 'Scenario_may_137', 'Scenario_january_242', 'Scenario_december_024', 'Scenario_october_111', 'Scenario_july_303', 'Scenario_october_258', 'Scenario_february_149', 'Scenario_april_113', 'Scenario_june_243', 'Scenario_august_195', 'Scenario_september_017', 'Scenario_april_004', 'Scenario_june_318']
Num timesteps 30  survived timesteps: [8062, 2277, 3092, 3128, 158, 6618, 783, 3123, 6572, 243, 8062, 1116, 1975, 452, 591, 715, 4488, 1132, 971, 4301, 545, 6246, 1054, 8062, 8062, 2531, 2809, 2530, 8062, 1497]
-> Average survived timesteps: 3308.5666666666666
Memory used (GB): 1.50189208984375
Environment used: env_val Seed used: 3

Sin buckets (y 62+146 acciones)

$ python3.9 train.py Eval 30 0 & python3.9 train.py Eval 30 1 & python3.9 train.py Eval 30 2 & python3.9 train.py Eval 30 3

Episodes: ['Scenario_june_254', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_december_024', 'Scenario_june_004', 'Scenario_september_017', 'Scenario_january_183', 'Scenario_november_247', 'Scenario_april_220', 'Scenario_february_149', 'Scenario_july_303', 'Scenario_june_318', 'Scenario_august_167', 'Scenario_january_221', 'Scenario_april_113', 'Scenario_august_195', 'Scenario_march_059', 'Scenario_may_137', 'Scenario_january_242', 'Scenario_october_258', 'Scenario_august_210', 'Scenario_december_067', 'Scenario_march_106', 'Scenario_october_111', 'Scenario_october_017', 'Scenario_april_004', 'Scenario_june_243', 'Scenario_april_262', 'Scenario_january_132', 'Scenario_june_254']
Num timesteps 30  survived timesteps: [5992, 1632, 306, 8062, 2276, 123, 406, 8062, 1561, 8062, 8062, 2415, 239, 8062, 3567, 1975, 7134, 2374, 436, 8062, 1130, 2015, 4302, 566, 8062, 8062, 5984, 113, 8062, 2810]
-> Average survived timesteps: 3997.133333333333
Memory used (GB): 0.7247047424316406
Environment used: env_val Seed used: 0

Episodes: ['Scenario_june_254', 'Scenario_april_004', 'Scenario_january_221', 'Scenario_august_195', 'Scenario_october_111', 'Scenario_july_303', 'Scenario_december_067', 'Scenario_january_242', 'Scenario_october_017', 'Scenario_june_318', 'Scenario_march_059', 'Scenario_august_167', 'Scenario_april_262', 'Scenario_november_247', 'Scenario_april_113', 'Scenario_december_024', 'Scenario_august_210', 'Scenario_april_220', 'Scenario_february_149', 'Scenario_october_258', 'Scenario_september_017', 'Scenario_january_183', 'Scenario_june_004', 'Scenario_january_132', 'Scenario_march_106', 'Scenario_june_243', 'Scenario_may_137', 'Scenario_february_132', 'Scenario_august_151', 'Scenario_june_254']
Num timesteps 30  survived timesteps: [1646, 305, 2300, 2282, 7478, 385, 189, 580, 8062, 3123, 2415, 5994, 1538, 8062, 1976, 8062, 7130, 2864, 425, 1131, 2015, 8062, 411, 422, 8062, 5980, 1546, 3098, 8062, 2530]
-> Average survived timesteps: 3537.8333333333335
Memory used (GB): 0.7568702697753906
Environment used: env_val Seed used: 1

Episodes: ['Scenario_january_242', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_april_220', 'Scenario_january_221', 'Scenario_august_210', 'Scenario_october_111', 'Scenario_june_004', 'Scenario_march_106', 'Scenario_october_258', 'Scenario_february_149', 'Scenario_april_004', 'Scenario_august_167', 'Scenario_april_262', 'Scenario_january_183', 'Scenario_december_024', 'Scenario_august_195', 'Scenario_april_113', 'Scenario_march_059', 'Scenario_july_303', 'Scenario_november_247', 'Scenario_may_137', 'Scenario_december_067', 'Scenario_june_243', 'Scenario_october_017', 'Scenario_january_132', 'Scenario_june_318', 'Scenario_september_017', 'Scenario_june_254', 'Scenario_january_242']
Num timesteps 30  survived timesteps: [8062, 10, 5101, 2522, 8062, 4894, 8062, 1662, 738, 2818, 5997, 8062, 8062, 1975, 1144, 8062, 7126, 1653, 8062, 122, 8062, 533, 8062, 887, 1275, 8062, 1605, 8062, 509, 2703]
-> Average survived timesteps: 4398.533333333334
Memory used (GB): 0.7570648193359375
Environment used: env_val Seed used: 2

Episodes: ['Scenario_june_318', 'Scenario_august_151', 'Scenario_february_132', 'Scenario_april_262', 'Scenario_april_220', 'Scenario_november_247', 'Scenario_june_254', 'Scenario_december_067', 'Scenario_march_059', 'Scenario_august_210', 'Scenario_january_132', 'Scenario_august_167', 'Scenario_june_004', 'Scenario_march_106', 'Scenario_january_183', 'Scenario_october_017', 'Scenario_january_221', 'Scenario_may_137', 'Scenario_january_242', 'Scenario_december_024', 'Scenario_october_111', 'Scenario_july_303', 'Scenario_october_258', 'Scenario_february_149', 'Scenario_april_113', 'Scenario_june_243', 'Scenario_august_195', 'Scenario_september_017', 'Scenario_april_004', 'Scenario_june_318']
Num timesteps 30  survived timesteps: [8062, 251, 2536, 3128, 165, 8062, 783, 3123, 6572, 239, 8062, 7503, 1975, 447, 591, 716, 8062, 1132, 971, 4302, 545, 422, 1043, 8062, 8062, 2537, 2811, 2530, 8062, 1497]
-> Average survived timesteps: 3408.4333333333334
Memory used (GB): 0.7658309936523438
Environment used: env_val Seed used: 3


>>>>>>>>>>>>>>>>>>>

1255 vs 46+146
(0.8 min rho)

1255 (0.8 min rho):

$ python3.9 train.py EvalInTraining 50 0 & python3.9 train.py EvalInTraining 50 1

Episodes: ['Scenario_april_034', 'Scenario_february_066', 'Scenario_january_215', 'Scenario_december_238', 'Scenario_october_177', 'Scenario_november_117', 'Scenario_december_004', 'Scenario_february_050', 'Scenario_april_211', 'Scenario_may_059', 'Scenario_december_234', 'Scenario_march_002', 'Scenario_may_027', 'Scenario_december_025', 'Scenario_april_196', 'Scenario_october_087', 'Scenario_march_075', 'Scenario_november_186', 'Scenario_december_138', 'Scenario_december_042', 'Scenario_august_212', 'Scenario_june_270', 'Scenario_march_151', 'Scenario_july_085', 'Scenario_may_275', 'Scenario_august_251', 'Scenario_september_181', 'Scenario_october_197', 'Scenario_october_234', 'Scenario_february_142', 'Scenario_december_267', 'Scenario_may_298', 'Scenario_may_071', 'Scenario_july_353', 'Scenario_november_036', 'Scenario_july_003', 'Scenario_july_265', 'Scenario_february_055', 'Scenario_june_260', 'Scenario_june_242', 'Scenario_december_097', 'Scenario_march_018', 'Scenario_april_130', 'Scenario_march_254', 'Scenario_october_107', 'Scenario_july_130', 'Scenario_december_248', 'Scenario_june_052', 'Scenario_may_010', 'Scenario_june_343']
Num timesteps 50  survived timesteps: [434, 1632, 305, 12, 1025, 504, 384, 316, 4812, 791, 3120, 3684, 1584, 2061, 617, 1961, 151, 111, 2870, 342, 215, 2015, 4287, 187, 3806, 1087, 290, 431, 125, 740, 487, 85, 623, 1381, 787, 4351, 151, 7401, 4279, 582, 327, 650, 1948, 824, 2267, 1070, 552, 3982, 506, 1372]
-> Average survived timesteps: 1470.48
Memory used (GB): 1.5623207092285156
Environment used: env_train Seed used: 0

Episodes: ['Scenario_may_151', 'Scenario_june_096', 'Scenario_april_228', 'Scenario_july_089', 'Scenario_august_121', 'Scenario_november_144', 'Scenario_june_302', 'Scenario_october_193', 'Scenario_january_148', 'Scenario_march_163', 'Scenario_august_246', 'Scenario_february_184', 'Scenario_november_159', 'Scenario_september_156', 'Scenario_december_086', 'Scenario_august_239', 'Scenario_november_174', 'Scenario_september_237', 'Scenario_february_103', 'Scenario_april_149', 'Scenario_february_256', 'Scenario_february_182', 'Scenario_december_079', 'Scenario_october_021', 'Scenario_january_233', 'Scenario_november_085', 'Scenario_december_263', 'Scenario_september_218', 'Scenario_january_116', 'Scenario_august_022', 'Scenario_august_063', 'Scenario_october_068', 'Scenario_july_158', 'Scenario_june_143', 'Scenario_december_042', 'Scenario_february_072', 'Scenario_april_001', 'Scenario_february_116', 'Scenario_march_148', 'Scenario_may_031', 'Scenario_march_242', 'Scenario_february_201', 'Scenario_august_122', 'Scenario_october_136', 'Scenario_december_154', 'Scenario_march_247', 'Scenario_september_020', 'Scenario_november_007', 'Scenario_october_035', 'Scenario_april_058']
Num timesteps 50  survived timesteps: [3784, 303, 2954, 121, 141, 4181, 118, 520, 798, 3120, 218, 413, 1047, 138, 2372, 224, 7130, 699, 1055, 1134, 122, 2049, 279, 740, 260, 768, 1033, 1489, 2082, 487, 84, 623, 217, 1135, 137, 4863, 507, 3948, 579, 302, 653, 1837, 152, 164, 4150, 571, 652, 154, 1053, 570]
-> Average survived timesteps: 1242.6
Memory used (GB): 1.5633430480957031
Environment used: env_train Seed used: 1


46+146 (0.8 min rho):

$ python3.9 train.py EvalInTraining 50 0 & python3.9 train.py EvalInTraining 50 1

Episodes: ['Scenario_april_034', 'Scenario_february_066', 'Scenario_january_215', 'Scenario_december_238', 'Scenario_october_177', 'Scenario_november_117', 'Scenario_december_004', 'Scenario_february_050', 'Scenario_april_211', 'Scenario_may_059', 'Scenario_december_234', 'Scenario_march_002', 'Scenario_may_027', 'Scenario_december_025', 'Scenario_april_196', 'Scenario_october_087', 'Scenario_march_075', 'Scenario_november_186', 'Scenario_december_138', 'Scenario_december_042', 'Scenario_august_212', 'Scenario_june_270', 'Scenario_march_151', 'Scenario_july_085', 'Scenario_may_275', 'Scenario_august_251', 'Scenario_september_181', 'Scenario_october_197', 'Scenario_october_234', 'Scenario_february_142', 'Scenario_december_267', 'Scenario_may_298', 'Scenario_may_071', 'Scenario_july_353', 'Scenario_november_036', 'Scenario_july_003', 'Scenario_july_265', 'Scenario_february_055', 'Scenario_june_260', 'Scenario_june_242', 'Scenario_december_097', 'Scenario_march_018', 'Scenario_april_130', 'Scenario_march_254', 'Scenario_october_107', 'Scenario_july_130', 'Scenario_december_248', 'Scenario_june_052', 'Scenario_may_010', 'Scenario_june_343']
Num timesteps 50  survived timesteps: [412, 1331, 305, 11, 1025, 168, 384, 8062, 8062, 778, 3120, 8062, 786, 7613, 617, 1975, 429, 591, 1023, 1661, 8062, 2015, 8062, 4093, 8062, 1080, 287, 130, 1546, 1040, 8062, 816, 8062, 692, 1169, 6033, 128, 8062, 8062, 582, 349, 3091, 1948, 143, 903, 258, 8062, 2662, 8062, 1372]
-> Average survived timesteps: 2986.2
Memory used (GB): 0.9860992431640625
Environment used: env_train Seed used: 0


Episodes: ['Scenario_may_151', 'Scenario_june_096', 'Scenario_april_228', 'Scenario_july_089', 'Scenario_august_121', 'Scenario_november_144', 'Scenario_june_302', 'Scenario_october_193', 'Scenario_january_148', 'Scenario_march_163', 'Scenario_august_246', 'Scenario_february_184', 'Scenario_november_159', 'Scenario_september_156', 'Scenario_december_086', 'Scenario_august_239', 'Scenario_november_174', 'Scenario_september_237', 'Scenario_february_103', 'Scenario_april_149', 'Scenario_february_256', 'Scenario_february_182', 'Scenario_december_079', 'Scenario_october_021', 'Scenario_january_233', 'Scenario_november_085', 'Scenario_december_263', 'Scenario_september_218', 'Scenario_january_116', 'Scenario_august_022', 'Scenario_august_063', 'Scenario_october_068', 'Scenario_july_158', 'Scenario_june_143', 'Scenario_december_042', 'Scenario_february_072', 'Scenario_april_001', 'Scenario_february_116', 'Scenario_march_148', 'Scenario_may_031', 'Scenario_march_242', 'Scenario_february_201', 'Scenario_august_122', 'Scenario_october_136', 'Scenario_december_154', 'Scenario_march_247', 'Scenario_september_020', 'Scenario_november_007', 'Scenario_october_035', 'Scenario_april_058']
Num timesteps 50  survived timesteps: [4275, 5611, 7562, 154, 420, 8062, 167, 520, 802, 4063, 796, 258, 1046, 614, 7537, 1145, 8062, 2864, 7443, 457, 131, 996, 279, 1085, 160, 711, 1556, 711, 2811, 2556, 84, 8062, 8062, 1023, 525, 4863, 2843, 4281, 2124, 302, 653, 3735, 822, 314, 4241, 603, 117, 190, 3084, 6628]
-> Average survived timesteps: 2508.2
Memory used (GB): 0.9754219055175781
Environment used: env_train Seed used: 1


Ahora con 1.0 min rho:

$ python3.9 train.py EvalInTraining 50 0 & python3.9 train.py EvalInTraining 50 1
(1.0 rho)
1255 buckets

Episodes: ['Scenario_april_034', 'Scenario_february_066', 'Scenario_january_215', 'Scenario_december_238', 'Scenario_october_177', 'Scenario_november_117', 'Scenario_december_004', 'Scenario_february_050', 'Scenario_april_211', 'Scenario_may_059', 'Scenario_december_234', 'Scenario_march_002', 'Scenario_may_027', 'Scenario_december_025', 'Scenario_april_196', 'Scenario_october_087', 'Scenario_march_075', 'Scenario_november_186', 'Scenario_december_138', 'Scenario_december_042', 'Scenario_august_212', 'Scenario_june_270', 'Scenario_march_151', 'Scenario_july_085', 'Scenario_may_275', 'Scenario_august_251', 'Scenario_september_181', 'Scenario_october_197', 'Scenario_october_234', 'Scenario_february_142', 'Scenario_december_267', 'Scenario_may_298', 'Scenario_may_071', 'Scenario_july_353', 'Scenario_november_036', 'Scenario_july_003', 'Scenario_july_265', 'Scenario_february_055', 'Scenario_june_260', 'Scenario_june_242', 'Scenario_december_097', 'Scenario_march_018', 'Scenario_april_130', 'Scenario_march_254', 'Scenario_october_107', 'Scenario_july_130', 'Scenario_december_248', 'Scenario_june_052', 'Scenario_may_010', 'Scenario_june_343']
Num timesteps 50  survived timesteps: [558, 1632, 305, 12, 1030, 168, 382, 8062, 8062, 797, 3123, 6572, 2678, 6520, 617, 1976, 1146, 591, 4748, 1662, 8062, 2015, 1354, 3481, 8062, 8062, 289, 2032, 2500, 1142, 8062, 4929, 8062, 692, 1665, 5701, 1716, 8062, 8062, 582, 2222, 3092, 1948, 824, 8062, 1147, 4296, 2648, 5440, 1372]
-> Average survived timesteps: 3324.48
Memory used (GB): 1.5161514282226562
Environment used: env_train Seed used: 0

Episodes: ['Scenario_may_151', 'Scenario_june_096', 'Scenario_april_228', 'Scenario_july_089', 'Scenario_august_121', 'Scenario_november_144', 'Scenario_june_302', 'Scenario_october_193', 'Scenario_january_148', 'Scenario_march_163', 'Scenario_august_246', 'Scenario_february_184', 'Scenario_november_159', 'Scenario_september_156', 'Scenario_december_086', 'Scenario_august_239', 'Scenario_november_174', 'Scenario_september_237', 'Scenario_february_103', 'Scenario_april_149', 'Scenario_february_256', 'Scenario_february_182', 'Scenario_december_079', 'Scenario_october_021', 'Scenario_january_233', 'Scenario_november_085', 'Scenario_december_263', 'Scenario_september_218', 'Scenario_january_116', 'Scenario_august_022', 'Scenario_august_063', 'Scenario_october_068', 'Scenario_july_158', 'Scenario_june_143', 'Scenario_december_042', 'Scenario_february_072', 'Scenario_april_001', 'Scenario_february_116', 'Scenario_march_148', 'Scenario_may_031', 'Scenario_march_242', 'Scenario_february_201', 'Scenario_august_122', 'Scenario_october_136', 'Scenario_december_154', 'Scenario_march_247', 'Scenario_september_020', 'Scenario_november_007', 'Scenario_october_035', 'Scenario_april_058']
Num timesteps 50  survived timesteps: [8062, 6583, 6643, 2279, 2499, 8062, 167, 524, 801, 4835, 1874, 240, 1043, 617, 8062, 1145, 7130, 2864, 1660, 1131, 2015, 4295, 279, 4913, 265, 1276, 1564, 2496, 2804, 5586, 294, 8062, 7128, 822, 2234, 4863, 515, 3947, 8062, 302, 656, 8062, 103, 832, 7979, 553, 652, 171, 3095, 8062]
-> Average survived timesteps: 3162.16
Memory used (GB): 1.5161819458007812
Environment used: env_train Seed used: 1

$ python3.9 train.py EvalInTraining 50 0 & python3.9 train.py EvalInTraining 50 1
(1.0 rho)
62+142 buckets:

Episodes: ['Scenario_april_034', 'Scenario_february_066', 'Scenario_january_215', 'Scenario_december_238', 'Scenario_october_177', 'Scenario_november_117', 'Scenario_december_004', 'Scenario_february_050', 'Scenario_april_211', 'Scenario_may_059', 'Scenario_december_234', 'Scenario_march_002', 'Scenario_may_027', 'Scenario_december_025', 'Scenario_april_196', 'Scenario_october_087', 'Scenario_march_075', 'Scenario_november_186', 'Scenario_december_138', 'Scenario_december_042', 'Scenario_august_212', 'Scenario_june_270', 'Scenario_march_151', 'Scenario_july_085', 'Scenario_may_275', 'Scenario_august_251', 'Scenario_september_181', 'Scenario_october_197', 'Scenario_october_234', 'Scenario_february_142', 'Scenario_december_267', 'Scenario_may_298', 'Scenario_may_071', 'Scenario_july_353', 'Scenario_november_036', 'Scenario_july_003', 'Scenario_july_265', 'Scenario_february_055', 'Scenario_june_260', 'Scenario_june_242', 'Scenario_december_097', 'Scenario_march_018', 'Scenario_april_130', 'Scenario_march_254', 'Scenario_october_107', 'Scenario_july_130', 'Scenario_december_248', 'Scenario_june_052', 'Scenario_may_010', 'Scenario_june_343']
Num timesteps 50  survived timesteps: [558, 1632, 305, 11, 1659, 168, 384, 8062, 8062, 778, 3123, 8062, 2263, 8062, 617, 1975, 1144, 591, 4729, 1662, 8062, 2018, 8062, 8062, 8062, 8062, 289, 2035, 2500, 1142, 8062, 4929, 8062, 692, 1665, 5701, 737, 8062, 8062, 582, 2222, 3092, 1948, 824, 873, 1127, 8062, 3982, 5440, 1375]
-> Average survived timesteps: 3552.8
Memory used (GB): 0.7999725341796875
Environment used: env_train Seed used: 0

Episodes: ['Scenario_may_151', 'Scenario_june_096', 'Scenario_april_228', 'Scenario_july_089', 'Scenario_august_121', 'Scenario_november_144', 'Scenario_june_302', 'Scenario_october_193', 'Scenario_january_148', 'Scenario_march_163', 'Scenario_august_246', 'Scenario_february_184', 'Scenario_november_159', 'Scenario_september_156', 'Scenario_december_086', 'Scenario_august_239', 'Scenario_november_174', 'Scenario_september_237', 'Scenario_february_103', 'Scenario_april_149', 'Scenario_february_256', 'Scenario_february_182', 'Scenario_december_079', 'Scenario_october_021', 'Scenario_january_233', 'Scenario_november_085', 'Scenario_december_263', 'Scenario_september_218', 'Scenario_january_116', 'Scenario_august_022', 'Scenario_august_063', 'Scenario_october_068', 'Scenario_july_158', 'Scenario_june_143', 'Scenario_december_042', 'Scenario_february_072', 'Scenario_april_001', 'Scenario_february_116', 'Scenario_march_148', 'Scenario_may_031', 'Scenario_march_242', 'Scenario_february_201', 'Scenario_august_122', 'Scenario_october_136', 'Scenario_december_154', 'Scenario_march_247', 'Scenario_september_020', 'Scenario_november_007', 'Scenario_october_035', 'Scenario_april_058']
Num timesteps 50  survived timesteps: [8062, 6583, 6643, 2283, 448, 8062, 186, 524, 796, 4840, 3554, 240, 1068, 617, 8062, 1145, 7133, 734, 1663, 1131, 2015, 4295, 279, 4913, 265, 1277, 2035, 2496, 2808, 5586, 296, 8062, 7128, 822, 2234, 4863, 506, 3948, 8062, 302, 653, 8062, 822, 833, 7978, 553, 652, 192, 3096, 8062]
-> Average survived timesteps: 3137.38
Memory used (GB): 0.8556785583496094
Environment used: env_train Seed used: 1

$ python3.9 train.py EvalInTraining 50 0 & python3.9 train.py EvalInTraining 50 1
(1.0 rho)
62 buckets:

Episodes: ['Scenario_april_034', 'Scenario_february_066', 'Scenario_january_215', 'Scenario_december_238', 'Scenario_october_177', 'Scenario_november_117', 'Scenario_december_004', 'Scenario_february_050', 'Scenario_april_211', 'Scenario_may_059', 'Scenario_december_234', 'Scenario_march_002', 'Scenario_may_027', 'Scenario_december_025', 'Scenario_april_196', 'Scenario_october_087', 'Scenario_march_075', 'Scenario_november_186', 'Scenario_december_138', 'Scenario_december_042', 'Scenario_august_212', 'Scenario_june_270', 'Scenario_march_151', 'Scenario_july_085', 'Scenario_may_275', 'Scenario_august_251', 'Scenario_september_181', 'Scenario_october_197', 'Scenario_october_234', 'Scenario_february_142', 'Scenario_december_267', 'Scenario_may_298', 'Scenario_may_071', 'Scenario_july_353', 'Scenario_november_036', 'Scenario_july_003', 'Scenario_july_265', 'Scenario_february_055', 'Scenario_june_260', 'Scenario_june_242', 'Scenario_december_097', 'Scenario_march_018', 'Scenario_april_130', 'Scenario_march_254', 'Scenario_october_107', 'Scenario_july_130', 'Scenario_december_248', 'Scenario_june_052', 'Scenario_may_010', 'Scenario_june_343']
Num timesteps 50  survived timesteps: [408, 1632, 305, 9, 1021, 124, 384, 286, 527, 783, 3123, 6574, 2251, 2289, 617, 1975, 1142, 591, 166, 1661, 8062, 2015, 8062, 537, 8062, 1070, 284, 2032, 2148, 1131, 2525, 802, 8062, 696, 1145, 5700, 722, 8062, 8062, 581, 302, 3091, 1948, 99, 8062, 1080, 570, 3986, 8062, 1372]
-> Average survived timesteps: 2484.0
Memory used (GB): 0.6331634521484375
Environment used: env_train Seed used: 0

Episodes: ['Scenario_may_151', 'Scenario_june_096', 'Scenario_april_228', 'Scenario_july_089', 'Scenario_august_121', 'Scenario_november_144', 'Scenario_june_302', 'Scenario_october_193', 'Scenario_january_148', 'Scenario_march_163', 'Scenario_august_246', 'Scenario_february_184', 'Scenario_november_159', 'Scenario_september_156', 'Scenario_december_086', 'Scenario_august_239', 'Scenario_november_174', 'Scenario_september_237', 'Scenario_february_103', 'Scenario_april_149', 'Scenario_february_256', 'Scenario_february_182', 'Scenario_december_079', 'Scenario_october_021', 'Scenario_january_233', 'Scenario_november_085', 'Scenario_december_263', 'Scenario_september_218', 'Scenario_january_116', 'Scenario_august_022', 'Scenario_august_063', 'Scenario_october_068', 'Scenario_july_158', 'Scenario_june_143', 'Scenario_december_042', 'Scenario_february_072', 'Scenario_april_001', 'Scenario_february_116', 'Scenario_march_148', 'Scenario_may_031', 'Scenario_march_242', 'Scenario_february_201', 'Scenario_august_122', 'Scenario_october_136', 'Scenario_december_154', 'Scenario_march_247', 'Scenario_september_020', 'Scenario_november_007', 'Scenario_october_035', 'Scenario_april_058']
Num timesteps 50  survived timesteps: [4264, 5098, 8062, 133, 2500, 8062, 177, 523, 783, 3108, 1184, 239, 1043, 617, 1976, 1142, 5383, 721, 1652, 1131, 131, 4295, 278, 434, 263, 1280, 2032, 2143, 2804, 2525, 293, 8062, 8062, 825, 140, 1715, 500, 3386, 8062, 302, 652, 1948, 105, 819, 7939, 553, 652, 187, 1372, 7714]
-> Average survived timesteps: 2345.42
Memory used (GB): 0.7896156311035156
Environment used: env_train Seed used: 1

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Tiempo de guardar info de episodes solo guardando rhos:

Episodes: ['Scenario_april_210', 'Scenario_december_127', 'Scenario_october_189', 'Scenario_july_302', 'Scenario_january_210', 'Scenario_april_023', 'Scenario_march_138', 'Scenario_july_111', 'Scenario_august_094', 'Scenario_august_225']
Num timesteps 10  survived timesteps: [822, 1634, 1936, 4626, 1021, 3097, 3131, 8062, 8062, 8062]
-> Average survived timesteps: 4045.3
Memory used (GB): 0.3209800720214844
Environment used: env_train Seed used: 0
FINISH!!

python3.9 store_episode_data.py EvalInTraining 10 1 0  2397,15s user 1,89s system 99% cpu 40:06,78 total


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Scores al correr $ test_submission:

Your scores are :
(remember these score are not at all an indication of what will be used in codalab, as the data it is tested on are really different):"

                 0             1
0            score     32.782531
1         duration   8716.180912
2  total_operation     45.475044
3  total_attention      3.166667

------------------------------------
         Extra Informations         
------------------------------------
Don't hesitate to have a look at:
        utils/last_submission_results/results.html
        utils/last_submission_results/*.gif
To have high level information about your agent.


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Eval con agente de ahora con alarma mala con 300 episodios:

$ python3.9 train.py Eval 280 1 0

Episodes: ['Scenario_june_116', 'Scenario_september_015', 'Scenario_march_109', 'Scenario_march_194', 'Scenario_august_187', 'Scenario_april_265', 'Scenario_november_104', 'Scenario_may_324', 'Scenario_august_011', 'Scenario_august_199', 'Scenario_october_015', 'Scenario_december_203', 'Scenario_july_090', 'Scenario_september_173', 'Scenario_august_269', 'Scenario_august_115', 'Scenario_september_131', 'Scenario_november_021', 'Scenario_may_164', 'Scenario_march_159', 'Scenario_april_150', 'Scenario_december_103', 'Scenario_november_204', 'Scenario_january_042', 'Scenario_june_015', 'Scenario_july_011', 'Scenario_august_229', 'Scenario_february_197', 'Scenario_september_076', 'Scenario_february_110', 'Scenario_october_213', 'Scenario_june_190', 'Scenario_august_251', 'Scenario_october_143', 'Scenario_april_075', 'Scenario_july_321', 'Scenario_april_252', 'Scenario_november_154', 'Scenario_april_173', 'Scenario_july_326', 'Scenario_september_097', 'Scenario_january_059', 'Scenario_december_122', 'Scenario_february_152', 'Scenario_october_212', 'Scenario_july_145', 'Scenario_march_097', 'Scenario_may_266', 'Scenario_march_201', 'Scenario_august_069', 'Scenario_december_258', 'Scenario_march_081', 'Scenario_march_002', 'Scenario_august_021', 'Scenario_december_143', 'Scenario_december_263', 'Scenario_may_355', 'Scenario_march_144', 'Scenario_june_319', 'Scenario_october_191', 'Scenario_october_088', 'Scenario_november_224', 'Scenario_february_148', 'Scenario_february_127', 'Scenario_november_092', 'Scenario_november_165', 'Scenario_april_143', 'Scenario_july_258', 'Scenario_february_113', 'Scenario_march_093', 'Scenario_august_043', 'Scenario_september_169', 'Scenario_february_005', 'Scenario_july_075', 'Scenario_march_013', 'Scenario_august_034', 'Scenario_april_261', 'Scenario_april_060', 'Scenario_september_265', 'Scenario_november_261', 'Scenario_july_327', 'Scenario_july_180', 'Scenario_august_222', 'Scenario_june_212', 'Scenario_april_207', 'Scenario_may_154', 'Scenario_may_059', 'Scenario_may_350', 'Scenario_october_249', 'Scenario_april_266', 'Scenario_october_205', 'Scenario_april_049', 'Scenario_may_351', 'Scenario_january_088', 'Scenario_may_210', 'Scenario_june_052', 'Scenario_august_266', 'Scenario_november_058', 'Scenario_september_031', 'Scenario_june_222', 'Scenario_may_344', 'Scenario_october_131', 'Scenario_february_134', 'Scenario_december_147', 'Scenario_december_002', 'Scenario_january_133', 'Scenario_december_211', 'Scenario_may_308', 'Scenario_may_286', 'Scenario_october_037', 'Scenario_september_162', 'Scenario_april_133', 'Scenario_march_045', 'Scenario_april_005', 'Scenario_february_195', 'Scenario_april_257', 'Scenario_june_206', 'Scenario_june_267', 'Scenario_may_180', 'Scenario_september_213', 'Scenario_november_079', 'Scenario_december_128', 'Scenario_february_136', 'Scenario_february_133', 'Scenario_september_116', 'Scenario_august_048', 'Scenario_february_072', 'Scenario_may_101', 'Scenario_april_035', 'Scenario_february_084', 'Scenario_january_036', 'Scenario_february_013', 'Scenario_august_133', 'Scenario_september_132', 'Scenario_june_335', 'Scenario_october_119', 'Scenario_october_269', 'Scenario_december_053', 'Scenario_may_041', 'Scenario_september_196', 'Scenario_august_240', 'Scenario_december_205', 'Scenario_november_024', 'Scenario_january_031', 'Scenario_march_218', 'Scenario_march_242', 'Scenario_february_040', 'Scenario_june_336', 'Scenario_october_241', 'Scenario_january_201', 'Scenario_february_126', 'Scenario_january_021', 'Scenario_february_155', 'Scenario_february_214', 'Scenario_july_261', 'Scenario_august_208', 'Scenario_april_085', 'Scenario_january_250', 'Scenario_october_176', 'Scenario_september_079', 'Scenario_december_054', 'Scenario_april_264', 'Scenario_april_084', 'Scenario_august_247', 'Scenario_november_117', 'Scenario_may_095', 'Scenario_march_059', 'Scenario_december_228', 'Scenario_september_263', 'Scenario_february_103', 'Scenario_september_206', 'Scenario_december_155', 'Scenario_january_130', 'Scenario_march_132', 'Scenario_march_148', 'Scenario_september_224', 'Scenario_december_242', 'Scenario_june_353', 'Scenario_december_057', 'Scenario_december_024', 'Scenario_november_093', 'Scenario_june_247', 'Scenario_september_024', 'Scenario_june_214', 'Scenario_june_171', 'Scenario_july_000', 'Scenario_january_217', 'Scenario_february_162', 'Scenario_october_174', 'Scenario_december_212', 'Scenario_august_254', 'Scenario_october_035', 'Scenario_march_227', 'Scenario_april_024', 'Scenario_august_092', 'Scenario_june_042', 'Scenario_september_055', 'Scenario_november_033', 'Scenario_december_236', 'Scenario_january_256', 'Scenario_december_255', 'Scenario_january_195', 'Scenario_march_018', 'Scenario_february_258', 'Scenario_march_200', 'Scenario_may_249', 'Scenario_january_052', 'Scenario_march_245', 'Scenario_august_204', 'Scenario_may_042', 'Scenario_july_251', 'Scenario_september_159', 'Scenario_may_352', 'Scenario_june_058', 'Scenario_december_161', 'Scenario_december_207', 'Scenario_august_165', 'Scenario_september_057', 'Scenario_january_142', 'Scenario_january_178', 'Scenario_february_037', 'Scenario_december_197', 'Scenario_june_124', 'Scenario_april_153', 'Scenario_july_262', 'Scenario_december_192', 'Scenario_march_232', 'Scenario_may_190', 'Scenario_july_055', 'Scenario_july_165', 'Scenario_march_134', 'Scenario_november_135', 'Scenario_january_204', 'Scenario_december_217', 'Scenario_february_154', 'Scenario_august_126', 'Scenario_november_113', 'Scenario_may_326', 'Scenario_february_066', 'Scenario_october_245', 'Scenario_august_012', 'Scenario_november_141', 'Scenario_march_145', 'Scenario_march_249', 'Scenario_february_157', 'Scenario_september_186', 'Scenario_june_226', 'Scenario_june_283', 'Scenario_february_139', 'Scenario_january_251', 'Scenario_january_022', 'Scenario_january_026', 'Scenario_march_223', 'Scenario_january_041', 'Scenario_january_192', 'Scenario_november_014', 'Scenario_june_354', 'Scenario_january_143', 'Scenario_july_081', 'Scenario_december_175', 'Scenario_january_065', 'Scenario_march_208', 'Scenario_june_011', 'Scenario_august_209', 'Scenario_july_060', 'Scenario_january_190', 'Scenario_may_356', 'Scenario_september_239', 'Scenario_may_263', 'Scenario_january_212', 'Scenario_may_175', 'Scenario_january_003', 'Scenario_june_188', 'Scenario_january_015', 'Scenario_may_274', 'Scenario_may_338', 'Scenario_january_014', 'Scenario_december_152', 'Scenario_june_342', 'Scenario_january_045']
Num timesteps 280  survived timesteps: [1953, 1648, 307, 14, 2277, 7161, 499, 8062, 8062, 8062, 3081, 1187, 8062, 2285, 635, 8062, 7124, 591, 8062, 1653, 8062, 975, 1920, 535, 8062, 8062, 3478, 120, 8062, 2789, 2525, 8062, 8062, 2218, 1674, 6033, 7599, 2847, 5456, 8062, 302, 652, 1570, 822, 288, 8062, 553, 4023, 2259, 8062, 361, 2232, 8062, 2268, 1370, 2491, 8062, 4610, 6058, 1180, 1372, 753, 15, 2447, 3573, 147, 7702, 3487, 1388, 6804, 8062, 8062, 288, 8062, 826, 8062, 7171, 7764, 815, 1178, 8062, 8062, 1551, 8062, 337, 8062, 3990, 8062, 285, 8062, 1337, 5141, 5985, 2452, 8062, 8062, 8062, 1948, 8062, 8062, 8062, 808, 601, 813, 617, 1242, 281, 3782, 8062, 125, 511, 8062, 5154, 4831, 270, 3697, 6342, 8062, 2923, 1098, 927, 247, 1065, 189, 5136, 3789, 4259, 8062, 8062, 502, 204, 1144, 4929, 6568, 8062, 938, 1105, 2484, 8062, 3393, 8062, 1039, 1573, 923, 6522, 936, 165, 8062, 1118, 366, 1821, 549, 593, 2391, 8062, 8062, 2360, 227, 1405, 3084, 1396, 6009, 460, 4263, 594, 8062, 481, 1381, 4957, 1900, 848, 561, 1718, 2529, 841, 815, 1160, 8062, 1698, 1113, 1216, 6086, 2015, 8062, 8062, 8062, 3385, 627, 168, 884, 8062, 332, 2226, 5679, 2563, 8062, 1429, 391, 74, 725, 1591, 972, 2251, 3605, 214, 8062, 420, 2595, 2835, 8062, 8062, 1645, 8062, 1484, 1106, 647, 2248, 1049, 666, 197, 1924, 1591, 8062, 1075, 8062, 671, 1400, 8062, 8062, 5117, 8062, 1018, 657, 7, 710, 5612, 376, 8062, 1960, 1317, 2811, 762, 207, 8062, 1851, 803, 8062, 8062, 830, 505, 1449, 3261, 1410, 523, 577, 71, 8062, 2526, 8062, 881, 251, 816, 8062, 1678, 8062, 976, 6750, 599, 8062, 506, 8062, 993, 8062, 1374, 8062, 8062, 740, 3107, 8062, 399]
Alarm scores [-200.0, -200.0, 42.666666666666664, 100.0, -200.0, -200.0, -200.0, 100.0, 100.0, 100.0, -200.0, 55.99999999999999, 100.0, -200.0, -200.0, 100.0, 55.99999999999999, -200.0, 100.0, -200.0, 100.0, 96.0, -200.0, -200.0, 100.0, 100.0, 96.0, -200.0, 100.0, -200.0, -200.0, 100.0, 100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, 100.0, -200.0, -200.0, -200.0, -200.0, -200.0, 100.0, -200.0, 84.0, 64.0, 100.0, -200.0, -200.0, 100.0, -200.0, -200.0, -200.0, 100.0, -200.0, -200.0, -200.0, -200.0, -200.0, 55.99999999999999, -200.0, -200.0, -200.0, 36.0, -200.0, 64.0, -200.0, 100.0, 100.0, -200.0, 100.0, 84.0, 100.0, -200.0, -200.0, -200.0, -200.0, 100.0, 100.0, -200.0, 100.0, -200.0, 100.0, -200.0, 100.0, 84.0, 100.0, -200.0, -200.0, 100.0, 64.0, 100.0, 100.0, 100.0, -200.0, 100.0, 100.0, 100.0, -200.0, 36.0, -200.0, -200.0, -200.0, -200.0, -200.0, 100.0, -200.0, -200.0, 100.0, -200.0, -200.0, 36.0, 36.0, -200.0, 100.0, 64.0, -200.0, -200.0, 84.0, -200.0, -200.0, -200.0, -200.0, -200.0, 100.0, 100.0, -200.0, 84.0, 36.0, -200.0, 24.0, 100.0, -200.0, -200.0, -200.0, 100.0, -200.0, 100.0, -200.0, -200.0, 100.0, -200.0, 96.0, -200.0, 100.0, -200.0, 55.99999999999999, -200.0, -200.0, -200.0, 36.0, 100.0, 100.0, 96.0, -200.0, -200.0, -200.0, -200.0, -200.0, 42.666666666666664, 84.0, 96.0, 100.0, -200.0, 36.0, 42.666666666666664, 36.0, -200.0, -200.0, -200.0, 55.99999999999999, -200.0, -200.0, -200.0, 100.0, -200.0, 96.0, -200.0, -200.0, -200.0, 100.0, 100.0, 100.0, -200.0, 36.0, -200.0, 96.0, 100.0, 84.0, -200.0, -200.0, 84.0, 100.0, -200.0, -200.0, -200.0, 64.0, -200.0, -200.0, -200.0, -200.0, 64.0, 100.0, -200.0, 84.0, -200.0, 100.0, 100.0, -200.0, 100.0, -200.0, -200.0, -200.0, -200.0, -200.0, 100.0, -200.0, -200.0, 64.0, 100.0, 100.0, 100.0, 96.0, 36.0, 100.0, 100.0, 84.0, 100.0, 64.0, -200.0, 36.0, 36.0, -200.0, -200.0, 100.0, -200.0, -200.0, 24.0, 36.0, 96.0, 100.0, 96.0, -200.0, 100.0, 100.0, 36.0, -200.0, -200.0, 36.0, -200.0, 84.0, -200.0, -200.0, 100.0, -200.0, 100.0, -200.0, -200.0, 84.0, 100.0, -200.0, 100.0, -200.0, 36.0, -200.0, 100.0, -200.0, 100.0, -200.0, 100.0, -200.0, 100.0, 100.0, -200.0, -200.0, 100.0, -200.0]
-> Average survived timesteps: 3586.260714285714
-> Average alarm score: -62.81428571428572


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

We want to avoid the last agent action being on the last timestep because the alarm thinks the game over was because of our action !!!!


Con la primera tanda de rhos 
Moralejas:

- Parece haber varios donde tener 0.9 en vez de 0.8 es un problema, paso en algunos que subia muy rapido de 0.9 a overflow sin dar lugar a usar la alarma.
(37%)

- Parece ser un problema que si hacemos una accion y en esa jugada se da el game over lo toma como que invalida la alarma !!!
(5%)

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Midiendo bien:

con rho 0.9, de 962 episodios tenemos:

- number_of_alarm_failures_due_to_no_info_in_previous_timesteps: 38,7% (373)
- number_of_alarm_failures_due_to_action_leading_to_game_over: 6,1% (59)

AHORA

con rho 0.8, de 196 episodios tenemos:

- number_of_alarm_failures_due_to_no_info_in_previous_timesteps: 23% (47)
- number_of_alarm_failures_due_to_action_leading_to_game_over: 6,6% (13)

Baja de 38,7% a 23%, OK. Probar con 0,7 ???

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Cosas que tenemos que tener en cuenta para mejorar:

-> min rho
-> Evitar que la accion sea lo que cause el gmae over !

> Usar el hecho de estar bajo ataque para elegir hacer una accion (ademas del criterio de que el rho sea < 1) ??

Agregar a store_episode_data:
- under_attack = info["opponent_attack_line"] is not None and len(info["opponent_attack_line"]) > 0
- obs.time_next_maintenance

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Podemos predecir cuando va a atacar el oponente ????

    'kwargs_opponent': {"lines_attacked": lines_attacked,
                        "attack_every_xxx_hour": 24,
                        "average_attack_duration_hour": 4,
                        "minimum_attack_duration_hour": 1},

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Cantidad que estan 'under_attack' vs no cuando perdemos (Para la alarma):

under_attack: 293
no_under_attack: 26

=> 92% de las veces que perdemos estamos under_attack !!!!

Importante agregar esto entonces:

- under_attack = info["opponent_attack_line"] is not None and len(info["opponent_attack_line"]) > 0
- obs.time_next_maintenance

(directamente meterle info["opponent_attack_line"])

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Hello,
Overflows are divided into two categories:
- the line is in overflow for too long
- the overflow on the line is too high (>200% of its thermal limit, or 150% of its limits, I don't remember)

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

number_of_alarm_failures_due_to_no_info_in_previous_timesteps

con 0.7 de rho tenemos 9% de los scenarios donde no visitamos el timestep 7 posiciones anterior al game over!
